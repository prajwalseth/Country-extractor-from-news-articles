{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from geotext import GeoText as GeoText2\n",
    "from flashgeotext.geotext import GeoText\n",
    "from flashgeotext.lookup import LookupData\n",
    "from operator import *\n",
    "import unidecode\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import collections, functools, operator\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_full = pd.read_excel('/Users/prajwal/Desktop/Koc/week5/v9 outputs/100 percent try4.xlsx')\n",
    "#df = pd.read_csv('/Users/prajwal/Desktop/Koc/week5/Cleaned data.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_full.sample(frac=0.01, replace=True, random_state=42)\n",
    "df = df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df.drop([\"Unnamed: 0\"],axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    df.drop([\"level_0\"],axis=1)\n",
    "except:\n",
    "    pass\n",
    "#df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73305\n"
     ]
    }
   ],
   "source": [
    "#df = df_full\n",
    "end_of_range = len(df)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = df.reset_index(drop=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_filter = pickle.load(open('dependencies/cities-1-and-2-filtered8.txt','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Montenegro',\n",
       " 'Oslo',\n",
       " 'Runcorn',\n",
       " 'Fresnes',\n",
       " 'Brazzaville',\n",
       " 'Auburn',\n",
       " 'Warwick',\n",
       " 'Khartoum',\n",
       " 'Armenia',\n",
       " 'Stellenbosch',\n",
       " 'Bīrganj',\n",
       " 'Ankara',\n",
       " 'Mönchengladbach',\n",
       " 'Bilbao',\n",
       " 'Cleveland',\n",
       " 'Patna',\n",
       " 'Riyadh',\n",
       " 'Brasília',\n",
       " 'Doha',\n",
       " 'Oceanside',\n",
       " 'Santiago',\n",
       " 'Flagstaff',\n",
       " 'Rājkot',\n",
       " 'Durango',\n",
       " 'Lebanon',\n",
       " 'Chicago',\n",
       " 'Gretna',\n",
       " 'Irvine',\n",
       " 'Melbourne',\n",
       " 'Dublin',\n",
       " 'Bannu',\n",
       " 'Baghdad',\n",
       " 'Quito',\n",
       " 'Gustavia',\n",
       " 'Kuche',\n",
       " 'Jarosław',\n",
       " 'Baltimore',\n",
       " 'Cheshire',\n",
       " 'Tonga',\n",
       " 'Benghazi',\n",
       " 'Vatican City',\n",
       " 'Nicosia',\n",
       " 'Urbana',\n",
       " 'Ljubljana',\n",
       " 'Yamaguchi-shi',\n",
       " 'Tippi',\n",
       " 'Krasnodar',\n",
       " 'Rabat',\n",
       " 'Ta‘izz',\n",
       " 'Hyderabad',\n",
       " 'Saint-Lô',\n",
       " 'Odessa',\n",
       " 'Ontario',\n",
       " 'Kathmandu',\n",
       " 'Safed',\n",
       " 'Santa Barbara',\n",
       " 'Brooklyn',\n",
       " 'Hongqiao',\n",
       " 'Gallatin',\n",
       " 'Skhirat',\n",
       " 'Bayeux',\n",
       " 'İstanbul',\n",
       " 'Puerto Vallarta',\n",
       " 'Rio de Janeiro',\n",
       " 'Albany',\n",
       " 'Budapest',\n",
       " 'Yokohama',\n",
       " 'La Madeleine',\n",
       " 'Trollhättan',\n",
       " 'Mumbai',\n",
       " 'Oakland',\n",
       " 'Bodø',\n",
       " 'Lisbon',\n",
       " 'Szeged',\n",
       " 'Thessaloníki',\n",
       " 'Lethbridge',\n",
       " 'Calais',\n",
       " 'Holiday',\n",
       " 'Catania',\n",
       " 'La Trinidad',\n",
       " 'Manzanillo',\n",
       " 'Al Mukallā',\n",
       " 'Pune',\n",
       " 'Male',\n",
       " 'Liberty',\n",
       " 'Keystone',\n",
       " 'Kassala',\n",
       " 'Guntūr',\n",
       " 'Yaoundé',\n",
       " 'Nizhniy Novgorod',\n",
       " 'Basel',\n",
       " 'Siena',\n",
       " 'Guangzhou',\n",
       " 'Pretoria',\n",
       " 'Hod HaSharon',\n",
       " 'Marbella',\n",
       " 'Concord',\n",
       " 'Alwar',\n",
       " 'İzmir',\n",
       " 'Logan',\n",
       " 'Malmesbury',\n",
       " 'Bislig',\n",
       " 'Glastonbury',\n",
       " 'Kolkata',\n",
       " 'Balad',\n",
       " 'Canberra',\n",
       " 'Bordeaux',\n",
       " 'Milton Keynes',\n",
       " 'Aurora',\n",
       " 'Donetsk',\n",
       " 'Sochi',\n",
       " 'DeSoto',\n",
       " 'Palangkaraya',\n",
       " 'Damascus',\n",
       " 'Baalbek',\n",
       " 'Bauru',\n",
       " 'Trento',\n",
       " 'Buenos Aires',\n",
       " 'Honda',\n",
       " 'Tripoli',\n",
       " 'Dallas',\n",
       " 'Maiduguri',\n",
       " 'NDjamena',\n",
       " 'Podgorica',\n",
       " 'Vila-real',\n",
       " 'Manama',\n",
       " 'Aleppo',\n",
       " 'Modesto',\n",
       " 'Kuala Lumpur',\n",
       " 'Marrakesh',\n",
       " 'Bradenton',\n",
       " 'Santa Catarina Pinula',\n",
       " 'Nottingham',\n",
       " 'City of Parramatta',\n",
       " 'Zagreb',\n",
       " 'Nazaré',\n",
       " 'Athens',\n",
       " 'Cambridge',\n",
       " 'Sanaa',\n",
       " 'Guatemala City',\n",
       " 'Beaumont',\n",
       " 'Perth',\n",
       " 'Alanya',\n",
       " 'Homer Glen',\n",
       " 'Yangon',\n",
       " 'Mytilíni',\n",
       " 'Amrāvati',\n",
       " 'Dortmund',\n",
       " 'Odense',\n",
       " 'Las Vegas',\n",
       " 'Mission',\n",
       " 'Hsinchu',\n",
       " 'Bucharest',\n",
       " 'Saint Petersburg',\n",
       " 'Diffa',\n",
       " 'Kano',\n",
       " 'Saint-Étienne',\n",
       " 'Kassel',\n",
       " 'Zürich',\n",
       " 'Jacksonville',\n",
       " 'Monterey',\n",
       " 'Richmond',\n",
       " 'San Miguelito',\n",
       " 'Sidi Slimane',\n",
       " 'Addis Ababa',\n",
       " 'Zenica',\n",
       " 'Bogotá',\n",
       " 'Nowa Sól',\n",
       " 'Liberal',\n",
       " 'Busan',\n",
       " 'Marseille',\n",
       " 'Laon',\n",
       " 'Lille',\n",
       " 'Bethesda',\n",
       " 'Macau',\n",
       " 'Johnson City',\n",
       " 'Madurai',\n",
       " 'Jakarta',\n",
       " 'Norwich',\n",
       " 'Rotterdam',\n",
       " 'Leicester',\n",
       " 'Houston',\n",
       " 'Malacca',\n",
       " 'Pop',\n",
       " 'Minneapolis',\n",
       " 'Antofagasta',\n",
       " 'Cincinnati',\n",
       " 'Brisbane',\n",
       " 'Metro',\n",
       " 'Central',\n",
       " 'Mexico City',\n",
       " 'Tours',\n",
       " 'Savannah',\n",
       " 'Reading',\n",
       " 'Spokane',\n",
       " 'Grasse',\n",
       " 'Roman',\n",
       " 'Beacon',\n",
       " 'Gwangju',\n",
       " 'Muscat',\n",
       " 'Qom',\n",
       " 'Brest',\n",
       " 'Derby',\n",
       " 'Bandar ‘Abbās',\n",
       " 'Dome',\n",
       " 'Seoul',\n",
       " 'Fukuoka-shi',\n",
       " 'The Valley',\n",
       " 'Valencia',\n",
       " 'Hermosa',\n",
       " 'Montana',\n",
       " 'Brent',\n",
       " 'Brookfield',\n",
       " 'Los Reyes',\n",
       " 'Cremona',\n",
       " 'Lào Cai',\n",
       " 'Eastbourne',\n",
       " 'Parang',\n",
       " 'Usman’',\n",
       " 'Dubai',\n",
       " 'Lausanne',\n",
       " 'Sligo',\n",
       " 'Ulsan',\n",
       " 'Edmonton',\n",
       " 'Daegu',\n",
       " 'Minsk',\n",
       " 'Durham',\n",
       " 'Middlesbrough',\n",
       " 'Winnipeg',\n",
       " 'Eau Claire',\n",
       " 'Xiamen',\n",
       " 'Rio Grande',\n",
       " 'Onex',\n",
       " 'La Romana',\n",
       " 'Norfolk',\n",
       " 'Kozhikode',\n",
       " 'Spring',\n",
       " 'Lagos',\n",
       " 'Bali',\n",
       " 'Aden',\n",
       " 'Dhaka',\n",
       " 'Gay',\n",
       " 'Whitley Bay',\n",
       " 'Date',\n",
       " 'La Roda',\n",
       " 'Liverpool',\n",
       " 'Manila',\n",
       " 'Florence',\n",
       " 'Meriden',\n",
       " 'Plantation',\n",
       " 'Lhasa',\n",
       " 'Adelaide',\n",
       " 'Virginia',\n",
       " 'Madrid',\n",
       " 'Medford',\n",
       " 'Rugby',\n",
       " 'Rome',\n",
       " 'Bear',\n",
       " 'Beirut',\n",
       " 'Alessandria',\n",
       " 'Abuja',\n",
       " 'Buriram',\n",
       " 'Golden',\n",
       " 'Derry',\n",
       " 'Schaumburg',\n",
       " 'Vienna',\n",
       " 'San',\n",
       " 'Beijing',\n",
       " 'Asia',\n",
       " 'Bath',\n",
       " 'Vevey',\n",
       " 'Hilton Head Island',\n",
       " 'Moscow',\n",
       " 'Quảng Ngãi',\n",
       " 'Liberia',\n",
       " 'Astana',\n",
       " 'Lucca',\n",
       " 'Gaya',\n",
       " 'Bell',\n",
       " 'Asheville',\n",
       " 'Rennes',\n",
       " 'Arkhangel’sk',\n",
       " 'Nice',\n",
       " 'Bournemouth',\n",
       " 'Rio Tinto',\n",
       " 'Lubbock',\n",
       " 'Karachi',\n",
       " 'Albuquerque',\n",
       " 'Halifax',\n",
       " 'Kiev',\n",
       " 'Bristol',\n",
       " 'Titusville',\n",
       " 'Washington',\n",
       " 'Vallejo',\n",
       " 'Le Port',\n",
       " 'Denpasar',\n",
       " 'Razgrad',\n",
       " 'Miami',\n",
       " 'Gateshead',\n",
       " 'Xinzhou',\n",
       " 'Sumber',\n",
       " 'Phrae',\n",
       " 'Duluth',\n",
       " 'Haiphong',\n",
       " 'Guildford',\n",
       " 'Yiyang',\n",
       " 'Young',\n",
       " 'Santo Domingo',\n",
       " 'Minden',\n",
       " 'St Helens',\n",
       " 'Ado Odo',\n",
       " 'Accra',\n",
       " 'Caracas',\n",
       " 'Nouakchott',\n",
       " 'Saskatoon',\n",
       " 'Manchester',\n",
       " 'Fort Myers',\n",
       " 'Tokyo',\n",
       " 'Wuhan',\n",
       " 'Lida',\n",
       " 'Munich',\n",
       " 'Dalian',\n",
       " 'Veere',\n",
       " 'Delta',\n",
       " 'Chiang Mai',\n",
       " 'Douai',\n",
       " 'Ranong',\n",
       " 'Watford',\n",
       " 'Delhi',\n",
       " 'Amman',\n",
       " 'Le Robert',\n",
       " 'Bratislava',\n",
       " 'Mobile',\n",
       " 'Lima',\n",
       " 'Thiruvananthapuram',\n",
       " 'Sơn La',\n",
       " 'Calabar',\n",
       " 'Prague',\n",
       " 'Porto',\n",
       " 'Cochin',\n",
       " 'Çorum',\n",
       " 'Sydney',\n",
       " 'Portland',\n",
       " 'Boston',\n",
       " 'Stratford',\n",
       " 'Ilorin',\n",
       " 'Le François',\n",
       " 'Barcelona',\n",
       " 'Glasgow',\n",
       " 'Rio Linda',\n",
       " 'Galle',\n",
       " 'Sale',\n",
       " 'Menton',\n",
       " 'Colombia',\n",
       " 'Luanda',\n",
       " 'Northampton',\n",
       " 'Worcester',\n",
       " 'Newry',\n",
       " 'Ahmedabad',\n",
       " 'Cheyenne',\n",
       " 'Berlin',\n",
       " 'Bonn',\n",
       " 'Piraeus',\n",
       " 'March',\n",
       " 'Hong Kong',\n",
       " 'Palo',\n",
       " 'Nanping',\n",
       " 'Vientiane',\n",
       " 'Sousse',\n",
       " 'D.C.',\n",
       " 'Bern',\n",
       " 'Tupelo',\n",
       " 'Milford',\n",
       " 'Casa Grande',\n",
       " 'San Juan',\n",
       " 'London',\n",
       " 'Quetta',\n",
       " 'Shenzhen',\n",
       " 'Turin',\n",
       " 'Tucson',\n",
       " 'Shagamu',\n",
       " 'Modena',\n",
       " 'Kearny']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count1 = 0\n",
    "cleaned_text = []\n",
    "language_of_text = []\n",
    "mega_list_of_names = {}\n",
    "#for i in range(0,len(df)):\n",
    "for i in range(0,end_of_range):\n",
    "    #print(i)\n",
    "    try:\n",
    "        cleaned_text_temp = str(df['text'][i]).replace('\\n',' ').replace(\"\\'\",\"'\").replace('_','').replace('—',' ').replace('--',' ')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        cleaned_text_temp = df['title'][i] + '. ' + cleaned_text_temp\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('Washington, D','D')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('Washington,D','D')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('Washington D','D')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('washington, d','d')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('washington,d','d')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('United States of America','United States')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('U.S. d','d')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('U.S. D','D')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('US D','D')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('US d','d')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('U.S D','D')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('U.S d','d')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('Latin America','Latin A')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('South America','South A')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('Copa America','Copa A')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace('North America','North A')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Xi'an\",'Xian')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Democratic Republic of Congo\",'DRC')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Republic of Congo\",'Rcongo')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Republic of the Congo\",'Rcongo')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Mexico City\",'Mexicocity')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"New England\",'Newengland')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"St. John's\",'Stjohns')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint John's\",'Stjohns')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"St. George's\",'Stgeorges')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint George's\",'Stgeorges')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Port of Spain\",'Portofspain')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Porto-Novo\",'Portonovo')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Porto Novo\",'Portonovo')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Port-au-Prince\",'Portauprince')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"East Jerusalem\",'Eastjerusalem')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Equatorial Guinea\",'Equatorialguinea')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Marshall Islands\",'Marshallislands')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Papua New Guinea\",'Papuanewguinea')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint Kitts and Nevis\",'Saintkittsandnevis')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint Kitts & Nevis\",'Saintkittsandnevis')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint Kitts\",'Saintkittsandnevis')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Nevis\",'Saintkittsandnevis')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint Lucia\",'Saintlucia')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint Vincent and the Grenadines\",'Saintvincentandthegrenadines')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint Vincent and the Grenadines\",'Saintvincentandthegrenadines')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Saint Vincent\",'Saintvincentandthegrenadines')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"St. Vincent\",'Saintvincentandthegrenadines')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Grenadines\",'Saintvincentandthegrenadines')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"South Sudan\",'Southsudan')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Trinidad and Tobago\",'Trinidadandtobago')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Trinidad & Tobago\",'Trinidadandtobago')\n",
    "        if 'Trinidadandtobago' not in cleaned_text_temp:\n",
    "            cleaned_text_temp = cleaned_text_temp.replace(\"Trinidad\",'Trinidadandtobago')\n",
    "            cleaned_text_temp = cleaned_text_temp.replace(\"Tobago\",'Trinidadandtobago')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"United Arab Emirates\",'Unitedarabemirates')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"Guinea-Bissau\",'Guineabissau')\n",
    "        cleaned_text_temp = cleaned_text_temp.replace(\"British Columbia\",'Britishcolumbia')\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #cleaned_text_temp = str(df['cleaned_text'][i]).replace('\\n',' ').replace(\"\\'\",\"'\").replace('_','')\n",
    "    \n",
    "    \n",
    "    \n",
    "    #doc = nlp(cleaned_text_temp[0:250])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    names_in_first100 = []\n",
    "    \n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if (ent.label_ == 'PERSON' and ent not in cities_filter):\n",
    "            names_in_first100.append(ent)\n",
    "            \n",
    "    #mega_list_of_names[i] = (names_in_first200)\n",
    "    \n",
    "    \n",
    "    for m in range(0,len(names_in_first100)):\n",
    "        \n",
    "        cleaned_text_temp = cleaned_text_temp.replace(str(names_in_first100[m]),'')\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_text.append(cleaned_text_temp)\n",
    "    \n",
    "    \n",
    "    #language_of_text.append(doc._.language['language'])\n",
    "    \n",
    "    \n",
    "    count1+=1\n",
    "\n",
    "cleaned_text2 = []\n",
    "#for i in range(0,len(df)):\n",
    "for i in range(0,end_of_range):\n",
    "    titlecase_for_capital = ''\n",
    "    for word in cleaned_text[i].split():\n",
    "        if(word.isupper()==True):\n",
    "            word = word.title()\n",
    "            titlecase_for_capital += word + ' '\n",
    "        else:\n",
    "            titlecase_for_capital += word + ' '\n",
    "    \n",
    "    cleaned_text2.append(titlecase_for_capital)\n",
    "\n",
    "for i in range(end_of_range, len(df)):\n",
    "    cleaned_text2.append('')\n",
    "\n",
    "df['cleaned_text'] = cleaned_text2\n",
    "\n",
    "\n",
    "#df['language'] = language_of_text\n",
    "\n",
    "try:\n",
    "    df = df.drop(['Unnamed: 0'],axis=1)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.94544816017151 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlist_cities_in_names2 = []\\nlist_cities_in_names_all = {}\\n\\nfor k in range(0, len(mega_list_of_names)):\\n    if mega_list_of_names[k] != []:\\n        for m in range(0,len(mega_list_of_names[k])):\\n            list_cities_in_names = list(dict(geotext.extract(input_text=str(mega_list_of_names[k][m]), span_info=False)).values())\\n            list_cities_in_names_all[k] = list_cities_in_names\\n            for n, i in enumerate(list_cities_in_names):\\n                if (n<1):\\n                    if i != {}:\\n                        #print(k, n, i)\\n                        list_cities_in_names2.append(list(list_cities_in_names[n])[0])\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "list_cities_in_names2 = []\n",
    "list_cities_in_names_all = {}\n",
    "\n",
    "for k in range(0, len(mega_list_of_names)):\n",
    "    if mega_list_of_names[k] != []:\n",
    "        for m in range(0,len(mega_list_of_names[k])):\n",
    "            list_cities_in_names = list(dict(geotext.extract(input_text=str(mega_list_of_names[k][m]), span_info=False)).values())\n",
    "            list_cities_in_names_all[k] = list_cities_in_names\n",
    "            for n, i in enumerate(list_cities_in_names):\n",
    "                if (n<1):\n",
    "                    if i != {}:\n",
    "                        #print(k, n, i)\n",
    "                        list_cities_in_names2.append(list(list_cities_in_names[n])[0])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlist_cities_in_names2 = list(dict.fromkeys(list_cities_in_names2))\\nprint(len(list_cities_in_names2))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "list_cities_in_names2 = list(dict.fromkeys(list_cities_in_names2))\n",
    "print(len(list_cities_in_names2))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"names3.txt\", \"wb\") as fp:   #Pickling\\n    pickle.dump(list_cities_in_names2, fp)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(\"names3.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(list_cities_in_names2, fp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_cities_in_names2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_names = (list(set(list_cities_in_names2) - set(checked_are_cities) - set(actual_people)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"names2.txt\", \"w\") as output:\\n    output.write(str(new_names))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(\"names2.txt\", \"w\") as output:\n",
    "    output.write(str(new_names))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnlp = spacy.load(\"en_core_web_sm\")\\ndoc = nlp(\"Madurai\")\\n\\nfor ent in doc.ents:\\n    print(ent.text, ent.start_char, ent.end_char, ent.label_)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Madurai\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport nltk\\nfrom nltk.tag.stanford import StanfordNERTagger as NERTagger\\nst = NERTagger(\\'/Users/prajwal/Desktop/stanford-ner-4.0.0/classifiers/english.all.3class.distsim.crf.ser.gz\\', \\'/Users/prajwal/Desktop/stanford-ner-4.0.0/stanford-ner.jar\\')\\ntext = \"My name is Akshat Singh and I\\'m from Arkhangel’sk\"\\n\\nfor sent in nltk.sent_tokenize(text):\\n    tokens = nltk.tokenize.word_tokenize(sent)\\n    tags = st.tag(tokens)\\n    for tag in tags:\\n        if tag[1]==\\'PERSON\\': print(tag)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import nltk\n",
    "from nltk.tag.stanford import StanfordNERTagger as NERTagger\n",
    "st = NERTagger('/Users/prajwal/Desktop/stanford-ner-4.0.0/classifiers/english.all.3class.distsim.crf.ser.gz', '/Users/prajwal/Desktop/stanford-ner-4.0.0/stanford-ner.jar')\n",
    "text = \"My name is Akshat Singh and I'm from Arkhangel’sk\"\n",
    "\n",
    "for sent in nltk.sent_tokenize(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(sent)\n",
    "    tags = st.tag(tokens)\n",
    "    for tag in tags:\n",
    "        if tag[1]=='PERSON': print(tag)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nf = open(\"names2.txt\", \"r\")\\nlist_of_names_to_check = f.read().replace(\\'\"\\',\\'\\').replace(\"[\",\\'\\').replace(\"]\",\\'\\').replace(\"\\'\",\\'\\').split(\\',\\')\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "f = open(\"names2.txt\", \"r\")\n",
    "list_of_names_to_check = f.read().replace('\"','').replace(\"[\",'').replace(\"]\",'').replace(\"'\",'').split(',')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nactual_people = []\\nfor i in range(0,len(list_of_names_to_check)):\\n    check_text = list_of_names_to_check[i]\\n    for sent in nltk.sent_tokenize(check_text):\\n        tokens = nltk.tokenize.word_tokenize(sent)\\n        tags = st.tag(tokens)\\n        for tag in tags:\\n            if tag[1]=='PERSON': \\n                print(tag)\\n                actual_people.append(tag[0])\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "actual_people = []\n",
    "for i in range(0,len(list_of_names_to_check)):\n",
    "    check_text = list_of_names_to_check[i]\n",
    "    for sent in nltk.sent_tokenize(check_text):\n",
    "        tokens = nltk.tokenize.word_tokenize(sent)\n",
    "        tags = st.tag(tokens)\n",
    "        for tag in tags:\n",
    "            if tag[1]=='PERSON': \n",
    "                print(tag)\n",
    "                actual_people.append(tag[0])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(1,len(list_of_names_to_check)):\\n    list_of_names_to_check[i] = list_of_names_to_check[i][1:]\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for i in range(1,len(list_of_names_to_check)):\n",
    "    list_of_names_to_check[i] = list_of_names_to_check[i][1:]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checked_are_cities = (list(set(list_of_names_to_check) - set(actual_people)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checked_are_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\nwith open(\"cities-filtered.txt\", \"wb\") as fp:   #Pickling\\n    pickle.dump(checked_are_cities, fp)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "with open(\"cities-filtered.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(checked_are_cities, fp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#actual_people = list(dict.fromkeys(actual_people))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(actual_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nremove_from_actual = ['Mönchengladbach','Bilbao','Busan','Monterey','Mytilíni','Zürich','Dortmund','Jarosław','Jāwad','İzmir','Yaoundé','Baltimore','Gustavia','Bogotá','Bodø','Thessaloníki','Trollhättan','İstanbul','Warwick','Bīrganj','Doha','Amrāvati','Nottingham','Nazaré','Petersburg','Saint-Étienne','Riyadh','Rājkot','Pune','Guntūr',]\\nfor i in range(0,len(remove_from_actual)):\\n    actual_people.remove(remove_from_actual[i])\\n    \\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove_from_actual = ['Monaco','Bologna','Ghandinagar', 'Cardona','Atherton','Kŭrdzhali','Lancaster','Bloomfield','Gilroy','Leverkusen','Westminster','Stafford','Sheffield','Cheltenham','Gujrāt','Newcastle','Stanton','Burnley','Blackburn','Ludhiāna','Montelíbano','Doha','Wolverhampton','Pune','Kota','Montgomery']\n",
    "#remove_from_actual = ['Ventura','Villagrán','Warburton','Nashua','Newbury','Ramona','Marlborough']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "remove_from_actual = ['Mönchengladbach','Bilbao','Busan','Monterey','Mytilíni','Zürich','Dortmund','Jarosław','Jāwad','İzmir','Yaoundé','Baltimore','Gustavia','Bogotá','Bodø','Thessaloníki','Trollhättan','İstanbul','Warwick','Bīrganj','Doha','Amrāvati','Nottingham','Nazaré','Petersburg','Saint-Étienne','Riyadh','Rājkot','Pune','Guntūr',]\n",
    "for i in range(0,len(remove_from_actual)):\n",
    "    actual_people.remove(remove_from_actual[i])\n",
    "    \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nadd_to_actual = ['Jāwad','Prospect']\\nfor i in range(0,len(add_to_actual)):\\n    actual_people.append(add_to_actual[i])\\n    checked_are_cities.remove(add_to_actual[i])\\n    \\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add_to_actual = ['Pout','Campbell','Best','Man','Ende','Sofia','Rogers','Pace','Normal','Rho','Tame','Nokia']\n",
    "\n",
    "\"\"\"\n",
    "add_to_actual = ['Jāwad','Prospect']\n",
    "for i in range(0,len(add_to_actual)):\n",
    "    actual_people.append(add_to_actual[i])\n",
    "    checked_are_cities.remove(add_to_actual[i])\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(actual_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\nwith open(\"cities-2-filtered.txt\", \"wb\") as fp:   #Pickling\\n    pickle.dump(checked_are_cities, fp)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "with open(\"cities-2-filtered.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(checked_are_cities, fp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\nwith open(\"names-2-filtered.txt\", \"wb\") as fp:   #Pickling\\n    pickle.dump(actual_people, fp)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "with open(\"names-2-filtered.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(actual_people, fp)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sorted(list_preds[86]['cities'].items(),key=lambda x:getitem(x[1],'count'), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nimport pprint\\npp = pprint.PrettyPrinter(indent=4)\\n\\n\\n#j = 963\\nj = 24\\n\\n\\npp.pprint(list_preds[j])\\nprint('\\n')\\nprint(df['pred_country_flashgeotext'][j],'\\n')\\nprint(df['pred_country_list_flashgeotext'][j],'\\n')\\nprint(df['cleaned_text'][j])\\n\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "#j = 963\n",
    "j = 24\n",
    "\n",
    "\n",
    "pp.pprint(list_preds[j])\n",
    "print('\\n')\n",
    "print(df['pred_country_flashgeotext'][j],'\\n')\n",
    "print(df['pred_country_list_flashgeotext'][j],'\\n')\n",
    "print(df['cleaned_text'][j])\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_these_words = ['March','Of', 'Union', 'Police', 'Normal', 'Central', \n",
    "                      'Most','Man','Mary','Roy','Bedi','Date','Along','Much',\n",
    "                      'University','Split','Tata','Nagar','Golden','George',\n",
    "                      'Sale','Stuart','Bar','Antony','Chidambaram','Wedding'\n",
    "                      'Antony','District','Correspondent','March','Photo','Mode',\n",
    "                      'IST', 'City', 'George','Corona','Ath','Frome','Federal','count',\n",
    "                      'Onex','David', 'Inđija','Plantation', 'Delta','Mission','Punch',\n",
    "                      'Wedi','Metro','West','Independence', 'Bay','Mon','Mons','Babu',\n",
    "                      'Begun','Sabha','Since','Zlin','Kars','Rugby','Marks',\n",
    "                      'Gary','Country Club','Van','Lopez','Tours','Parys','Stade',\n",
    "                      'Mora','Morsi','Temple','Nelson','Sparks','Siena','Anna','Rama',\n",
    "                      'Since','Caen','Apex','Sabhā','Sincé','Mataram','Clinton',\n",
    "                      'Obama','Kandahār','Tamils','Alliance','Nokia','Tak','Maun',\n",
    "                      'Samara','Rodriguez','Kati','Soma','Tomar','Dara','Marshall',\n",
    "                      'Paka','Best','Wādi','Thatta','The Valley','Swords','Pandi',\n",
    "                      'Pearl','Santee','Goa','Nago','Karaman','Nandu','Hammond','Buta',\n",
    "                      'Bid','Hassan','Mon','Pen','Amb','Martin','Hercules','Pen','Asia',\n",
    "                      'Male','Robert','Le Robert','Baní','Bern', 'Cordeirópolis', 'Pinto',\n",
    "                      'Whitney', 'Middleton', 'Edison', 'Alvin', 'Barry','Melo',\n",
    "                      'Carnegie', 'Clive', 'Mercedes', 'Ron','Liberal','Nigel','Borna',\n",
    "                      'Matthews','Warren','Mitchell','Stanton','Fairfax Media','Pinewood',\n",
    "                      'Bath','Bell','Brak','Lindi','Metz','San','Tyler','Wright','Elizabeth',\n",
    "                      'Nancy', 'Roth', 'Toba', 'Posse', 'Laurel', 'Holiday', 'Hastings', \n",
    "                      'Graham', 'Greeley', 'Deal', 'Bello', 'Alma','Young','Norman',\n",
    "                      'Columbia','Pop','Sake','Papa','Vic','Spring','Franklin','Griffin',\n",
    "                      'Como','Baar','Hamilton','Marina','Sunset','Bais','Lakewood','Green',\n",
    "                      'Pérez','Roseburg','Sebastian','Adam','Westlake','Cary','Harper',\n",
    "                      'Latin America','Stanley','Gap','Bryan','Cerro','Jos',\n",
    "                      'Machado','Torres','Garcia','Bentley','Nehe','Helena','Damme',\n",
    "                      'Mobile','Begūn','Nevers','Tara','Adler','Vladimir','Harper',\n",
    "                      'Bela','Dome','Gap','Reading','Frederick','Biga','Arona','Salt',\n",
    "                      'Phrae','Vitória','Santos','Izmayil','Dixon','Pérez', 'Molina', \n",
    "                      'Gálvez','Khanna','Kara','Ghat','Indija','Split','Castro','Minas',\n",
    "                      'Fleet','Ipoh','Summit','Manga','English','Manage','Worms','Banning',\n",
    "                      'Prince George','Vogan','Le Port','Flint','Dig','Durg','Osh','Trento',\n",
    "                      'Wa','Longview','Buy','Erba','Bear','Born', 'La Trinidad',\n",
    "                      \"Nuku‘alofa\", \"Port-au-Prince\", \"Port-of-Spain\", \"Saint George's\", \"St. John's\",\n",
    "                      'Gay', 'Sulphur', 'Co.', 'Brent', 'Una', 'Goes', 'Hi', 'Grasse','Münster', \n",
    "                      'Opportunity', 'Wyckoff','Gallup','Honda','Plunge','Luce','Surprise','Thān',\n",
    "                      'Than','Scarborough', 'La Possession', 'Superior','Voi','Prince Albert',\n",
    "                      'Dráma', 'Bam', 'Mi', 'Drama','Brits','Dax','Kula','Sim',\n",
    "                      'Shingū','Boo','Klin','Lucé','Lota','Aba','Peer','Ieper','Cañete',\n",
    "                      'Canning','Colón','Babat','Dour','Fatwa','Iba','Laon','Sama','Uman',\n",
    "                      'Saki','Bagé','Fargo','Logan','Pátra','Eagle','Palín','Chebba',\n",
    "                      'Humble','Rio Tinto','Gao','Palo','Centenario','Hong Kong','Rio Tinto',\n",
    "                      'Crystal','Magna','Itu','Butterworth','Pio','Salwá','Jena','Praia',\n",
    "                      'Cocoa','Asha','Benoy','Wedding','Leer','Liberty','Melle','Kaka','Nidda',\n",
    "                      'Ripley','Achim', 'Safed','Auerbach','Albany','Cambridge','Nederland',\n",
    "                      'Loni','Derby','Kashi','Dalai','Lamu','Shangri-La','Terrace','Sami',\n",
    "                      'Barking','Fleetwood','Weston','Porto','George Town','Granada','Palestine',\n",
    "                      'Guinea-Bissau','Jawhar'\n",
    "                      \n",
    "                     ]\n",
    "delete_these_places = ['Washington, D.C.', 'Washington']\n",
    "delete_these_words.extend(delete_these_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_these_also = pickle.load(open('dependencies/names-1-and-2-filtered8.txt','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Widnes',\n",
       " 'Sabhā',\n",
       " 'Columbus',\n",
       " 'Indi',\n",
       " 'Wakefield',\n",
       " 'Blaine',\n",
       " 'Christiana',\n",
       " 'Molina',\n",
       " 'Rheine',\n",
       " 'Samara',\n",
       " 'Esperanza',\n",
       " 'Clifton',\n",
       " 'Burton',\n",
       " 'Dole',\n",
       " 'Babu',\n",
       " 'Safi',\n",
       " 'Melville',\n",
       " 'Fuwah',\n",
       " 'Bria',\n",
       " 'Fontaine',\n",
       " 'Horst',\n",
       " 'Perris',\n",
       " 'Dādri',\n",
       " 'Numan',\n",
       " 'Kari',\n",
       " 'Keene',\n",
       " 'Napoli',\n",
       " 'Harwich',\n",
       " 'Keller',\n",
       " 'Altena',\n",
       " 'Haydock',\n",
       " 'Fondi',\n",
       " 'Chekhov',\n",
       " 'Randolph',\n",
       " 'Toki',\n",
       " 'Rezé',\n",
       " 'Saky',\n",
       " 'Gaspar',\n",
       " 'Massa',\n",
       " 'Takahashi',\n",
       " 'Brody',\n",
       " 'Norton',\n",
       " 'Easley',\n",
       " 'Alameda',\n",
       " 'Eden',\n",
       " 'Sherwood',\n",
       " 'Irving',\n",
       " 'Voerde',\n",
       " 'Sutton',\n",
       " 'Caivano',\n",
       " 'Antony',\n",
       " 'Terrell',\n",
       " 'Estelle',\n",
       " 'Gresham',\n",
       " 'Mercedes',\n",
       " 'Ara',\n",
       " 'Thornton',\n",
       " 'Selby',\n",
       " 'Markham',\n",
       " 'Hull',\n",
       " 'Vigo',\n",
       " 'Medina',\n",
       " 'Sari',\n",
       " 'Kasūr',\n",
       " 'Matiāri',\n",
       " 'Ōhara',\n",
       " 'Pau',\n",
       " 'Warburton',\n",
       " 'Tupi',\n",
       " 'Roosevelt',\n",
       " 'Bartlett',\n",
       " 'Mariano',\n",
       " 'Carrefour',\n",
       " 'Saint-André',\n",
       " 'Arona',\n",
       " 'Rafaḩ',\n",
       " 'Ghazni',\n",
       " 'Hatfield',\n",
       " 'Ajalpan',\n",
       " 'Ramsey',\n",
       " 'Carolina',\n",
       " 'Buffalo',\n",
       " 'Soria',\n",
       " 'Milas',\n",
       " 'Nizhniy',\n",
       " 'Novgorod',\n",
       " 'McDonough',\n",
       " 'Blyth',\n",
       " 'Assen',\n",
       " 'Burke',\n",
       " 'Salvador',\n",
       " 'Albemarle',\n",
       " 'Dyer',\n",
       " 'Nyborg',\n",
       " 'Saint-Louis',\n",
       " 'Kanda',\n",
       " 'Kalyān',\n",
       " 'Pinto',\n",
       " 'Baar',\n",
       " 'Rosenberg',\n",
       " 'Siuri',\n",
       " 'Bedford',\n",
       " 'Oviedo',\n",
       " 'Tiel',\n",
       " 'Mendoza',\n",
       " 'Morton',\n",
       " 'Yola',\n",
       " 'Chiba',\n",
       " 'Saint',\n",
       " 'Mahe',\n",
       " 'Radcliffe',\n",
       " 'Hille',\n",
       " 'Slonim',\n",
       " 'Oran',\n",
       " 'Sidi',\n",
       " 'Slimane',\n",
       " 'Aki',\n",
       " 'Werne',\n",
       " 'Huntley',\n",
       " 'Griffith',\n",
       " 'Gori',\n",
       " 'Ruma',\n",
       " 'Teresa',\n",
       " 'Girona',\n",
       " 'Hammond',\n",
       " 'Morsi',\n",
       " 'Westlake',\n",
       " 'Amos',\n",
       " 'Córdoba',\n",
       " 'Ānand',\n",
       " 'Kanekomachi',\n",
       " 'Melton',\n",
       " 'Miri',\n",
       " 'Canela',\n",
       " 'Murakami',\n",
       " 'Bela',\n",
       " 'Cranston',\n",
       " 'Monzón',\n",
       " 'Mariupol',\n",
       " 'Mariana',\n",
       " 'Marrero',\n",
       " 'Barrie',\n",
       " 'Vernon',\n",
       " 'Alicia',\n",
       " 'Cornelius',\n",
       " 'Hof',\n",
       " 'Barbosa',\n",
       " 'Zama',\n",
       " 'Sogcho',\n",
       " 'Mansfield',\n",
       " 'Troyan',\n",
       " 'Aso',\n",
       " 'Zemun',\n",
       " 'Hod',\n",
       " 'HaSharon',\n",
       " 'Enna',\n",
       " 'Nāwa',\n",
       " 'Sheridan',\n",
       " 'Kazan',\n",
       " 'Milton',\n",
       " 'Keynes',\n",
       " 'Kōnan',\n",
       " 'Roxas',\n",
       " 'Valls',\n",
       " 'Hatton',\n",
       " 'Speyer',\n",
       " 'Hagen',\n",
       " 'Lafayette',\n",
       " 'Matsumoto',\n",
       " 'Cairns',\n",
       " 'Lawton',\n",
       " 'Lancaster',\n",
       " 'Cueto',\n",
       " 'Patti',\n",
       " 'Alegre',\n",
       " 'Mut',\n",
       " 'Gulu',\n",
       " 'Alès',\n",
       " 'Goiás',\n",
       " 'Homer',\n",
       " 'Glen',\n",
       " 'Bilgi',\n",
       " 'Juba',\n",
       " 'Harper',\n",
       " 'Stirling',\n",
       " 'Garland',\n",
       " 'Wāling',\n",
       " 'Durant',\n",
       " 'Santee',\n",
       " 'Ajaccio',\n",
       " 'Tipton',\n",
       " 'Halle',\n",
       " 'Lacey',\n",
       " 'Biga',\n",
       " 'Monroe',\n",
       " 'Castro',\n",
       " 'Mandi',\n",
       " 'Sousa',\n",
       " 'Vista',\n",
       " 'Mendes',\n",
       " 'Pimentel',\n",
       " 'Borås',\n",
       " 'Kenner',\n",
       " 'Franca',\n",
       " 'Roth',\n",
       " 'Plato',\n",
       " 'La',\n",
       " 'Madeleine',\n",
       " 'Nanterre',\n",
       " 'Sevilla',\n",
       " 'Griffin',\n",
       " 'Middleton',\n",
       " 'Rosso',\n",
       " 'Sinan',\n",
       " 'Glan',\n",
       " 'Al',\n",
       " 'Mukallā',\n",
       " 'Stafford',\n",
       " 'Empoli',\n",
       " 'Palu',\n",
       " 'Rahden',\n",
       " 'Ramos',\n",
       " 'Leduc',\n",
       " 'Conde',\n",
       " 'Passos',\n",
       " 'Izumi',\n",
       " 'Bo',\n",
       " 'Westminster',\n",
       " 'Iglesias',\n",
       " 'Balfour',\n",
       " 'Rhondda',\n",
       " 'McKinney',\n",
       " 'Bissau',\n",
       " 'Preston',\n",
       " 'Ariana',\n",
       " 'Nehe',\n",
       " 'Metz',\n",
       " 'Marino',\n",
       " 'Parys',\n",
       " 'Hurst',\n",
       " 'Talladega',\n",
       " 'Saint-Germain-en-Laye',\n",
       " 'Lens',\n",
       " 'Jonesboro',\n",
       " 'Maldonado',\n",
       " 'Amancio',\n",
       " 'Brak',\n",
       " 'Malyn',\n",
       " 'Newton',\n",
       " 'Antioch',\n",
       " 'Norwood',\n",
       " 'Mons',\n",
       " 'Bais',\n",
       " 'Nowa',\n",
       " 'Sól',\n",
       " 'Vaughan',\n",
       " 'Jāwad',\n",
       " 'Prospect',\n",
       " 'David',\n",
       " 'Elizabeth',\n",
       " 'Chester',\n",
       " 'Lopez',\n",
       " 'Howard',\n",
       " 'Rosario',\n",
       " 'Morales',\n",
       " 'Rodriguez',\n",
       " 'Moore',\n",
       " 'Kyle',\n",
       " 'Corona',\n",
       " 'Ādam',\n",
       " 'Walker',\n",
       " 'Le',\n",
       " 'Robert',\n",
       " 'Los',\n",
       " 'Reyes',\n",
       " 'Whitley',\n",
       " 'Bay',\n",
       " 'Allen',\n",
       " 'Graham',\n",
       " 'Ron',\n",
       " 'Martin',\n",
       " 'Bello',\n",
       " 'León',\n",
       " 'Nancy',\n",
       " 'Arnold',\n",
       " 'Tucker',\n",
       " 'Lamont',\n",
       " 'Franklin',\n",
       " 'Tyler',\n",
       " 'Anderson',\n",
       " 'Roy',\n",
       " 'Nirmal',\n",
       " 'Douglas',\n",
       " 'Masuda',\n",
       " 'Langley',\n",
       " 'Harvey',\n",
       " 'Carney',\n",
       " 'Mitcham',\n",
       " 'Yara',\n",
       " 'Hudson',\n",
       " 'Motegi',\n",
       " 'Ho',\n",
       " 'Palma',\n",
       " 'Baldwin',\n",
       " 'Alvin',\n",
       " 'George',\n",
       " 'Izmayil',\n",
       " 'Warren',\n",
       " 'Austin',\n",
       " 'Taylor',\n",
       " 'Milano',\n",
       " 'Guarda',\n",
       " 'Feni',\n",
       " 'Torres',\n",
       " 'Hamilton',\n",
       " 'Chandler',\n",
       " 'Jefferson',\n",
       " 'Addison',\n",
       " 'Mitchell',\n",
       " 'Davenport',\n",
       " 'Hassan',\n",
       " 'Brad',\n",
       " 'Vaasa',\n",
       " 'Wavre',\n",
       " 'Badou',\n",
       " 'Matthews',\n",
       " 'Charlotte',\n",
       " 'Mary',\n",
       " 'Vitória',\n",
       " 'Gumi',\n",
       " 'Lindi',\n",
       " 'Verona',\n",
       " 'Atwater',\n",
       " 'Vincent',\n",
       " 'Green',\n",
       " 'Quarto',\n",
       " 'Zafar',\n",
       " 'Melo',\n",
       " 'Aldridge',\n",
       " 'Ratchaburi',\n",
       " 'Margherita',\n",
       " 'Fier',\n",
       " 'Wright',\n",
       " 'Savé',\n",
       " 'Madison',\n",
       " 'Caldwell',\n",
       " 'Evans',\n",
       " 'Hilliard',\n",
       " 'Lawrence',\n",
       " 'Roda',\n",
       " 'Kanye',\n",
       " 'Idlib',\n",
       " 'Batman',\n",
       " 'Nigel',\n",
       " 'Chelsea',\n",
       " 'Tara',\n",
       " 'Marshall',\n",
       " 'Parker',\n",
       " 'Hamm',\n",
       " 'Caen',\n",
       " 'Stanley',\n",
       " 'Van',\n",
       " 'Hopkins',\n",
       " 'García',\n",
       " 'Cochrane',\n",
       " 'Sanger',\n",
       " 'Jackson',\n",
       " 'Okāra',\n",
       " 'Lufkin',\n",
       " 'Wil',\n",
       " 'Saḩar',\n",
       " 'Kendall',\n",
       " 'Lyon',\n",
       " 'Lucas',\n",
       " 'Nikki',\n",
       " 'Cary',\n",
       " 'Nelson',\n",
       " 'Baden',\n",
       " 'Moe',\n",
       " 'Barry',\n",
       " 'Greenfield',\n",
       " 'Erie',\n",
       " 'Karlsruhe',\n",
       " 'Woodbury',\n",
       " 'Saiki',\n",
       " 'Flores',\n",
       " 'Holt',\n",
       " 'Augusta',\n",
       " 'Bolton',\n",
       " 'Maia',\n",
       " 'Vladimir',\n",
       " 'Steyr',\n",
       " 'Troy',\n",
       " 'Greenwood',\n",
       " 'Murphy',\n",
       " 'Fort',\n",
       " 'Myers',\n",
       " 'Anna',\n",
       " 'Gary',\n",
       " 'Obama',\n",
       " 'Eagan',\n",
       " 'Pūnch',\n",
       " 'Friedberg',\n",
       " 'Duncan',\n",
       " 'Lorena',\n",
       " 'Clinton',\n",
       " 'Wilson',\n",
       " 'Donna',\n",
       " 'Ferguson',\n",
       " 'Norman',\n",
       " 'Wheaton',\n",
       " 'Huy',\n",
       " 'Coro',\n",
       " 'Bari',\n",
       " 'Eugene',\n",
       " 'Napier',\n",
       " 'Oldham',\n",
       " 'Jos',\n",
       " 'Pápa',\n",
       " 'Wenjī',\n",
       " 'Vic',\n",
       " 'Carson',\n",
       " 'Santo',\n",
       " 'Domingo',\n",
       " 'Thun',\n",
       " 'Rivera',\n",
       " 'Palmer',\n",
       " 'Hilton',\n",
       " 'Head',\n",
       " 'Island',\n",
       " 'Findlay',\n",
       " 'Darwin',\n",
       " 'Sebastian',\n",
       " 'Acton',\n",
       " 'Haar',\n",
       " 'Paterson',\n",
       " 'Rio',\n",
       " 'Tinto',\n",
       " 'Reno',\n",
       " 'Mackay',\n",
       " 'Chiang',\n",
       " 'Mai',\n",
       " 'Kent',\n",
       " 'Ewing',\n",
       " 'Battersea',\n",
       " 'Wayne',\n",
       " 'Stuart',\n",
       " 'Bradley',\n",
       " 'Rocha',\n",
       " 'Taal',\n",
       " 'Paka',\n",
       " 'Bera',\n",
       " 'Liévin',\n",
       " 'Conway',\n",
       " 'Alba',\n",
       " 'Málaga',\n",
       " 'Lincoln',\n",
       " 'McLean',\n",
       " 'Tak',\n",
       " 'Gardner',\n",
       " 'Chico',\n",
       " 'Santos',\n",
       " 'Prince',\n",
       " 'Linda',\n",
       " 'Bryan',\n",
       " 'Holland',\n",
       " 'Brandon',\n",
       " 'Yuxi',\n",
       " 'Corcoran',\n",
       " 'Vera',\n",
       " 'Fontana',\n",
       " 'Kara',\n",
       " 'Patterson',\n",
       " 'Martinez',\n",
       " 'Muñoz',\n",
       " 'Harrison',\n",
       " 'Bucak',\n",
       " 'Hyde',\n",
       " 'Leigh',\n",
       " 'Wai',\n",
       " 'Béziers',\n",
       " 'Mao',\n",
       " 'Ariel',\n",
       " 'Davis',\n",
       " 'Floriano',\n",
       " 'Lynn',\n",
       " 'Constantine',\n",
       " 'Dara',\n",
       " 'Sparks',\n",
       " 'Morley',\n",
       " 'Holden',\n",
       " 'Nan',\n",
       " 'Jiashan',\n",
       " 'Johnston',\n",
       " 'Rohri',\n",
       " 'Poole',\n",
       " 'Morón',\n",
       " 'Ado',\n",
       " 'Odo',\n",
       " 'Richardson',\n",
       " 'Regina',\n",
       " 'Gilbert',\n",
       " 'Godfrey',\n",
       " 'Usman',\n",
       " '’',\n",
       " 'Westbrook',\n",
       " 'François',\n",
       " 'Hayward',\n",
       " 'Kaya',\n",
       " 'Solana',\n",
       " 'Sirjan',\n",
       " 'Avon',\n",
       " 'Hayes',\n",
       " 'Forster',\n",
       " 'Haan',\n",
       " 'Chía',\n",
       " 'Romsey',\n",
       " 'Ami',\n",
       " 'Bandar',\n",
       " '‘',\n",
       " 'Abbās',\n",
       " 'Tracy',\n",
       " 'Quảng',\n",
       " 'Ngãi',\n",
       " 'Adrian',\n",
       " 'Darien',\n",
       " 'Benton',\n",
       " 'Kobe',\n",
       " 'Salo',\n",
       " 'Minna',\n",
       " 'Paine',\n",
       " 'Monteiro',\n",
       " 'Congleton',\n",
       " 'Aalen',\n",
       " 'Hutchinson',\n",
       " 'Shirley',\n",
       " 'Jasper',\n",
       " 'Shelby',\n",
       " 'Hastings',\n",
       " 'Lào',\n",
       " 'Cai',\n",
       " 'Mora',\n",
       " 'Mori',\n",
       " 'Meda',\n",
       " 'Romana',\n",
       " 'Murray',\n",
       " 'Clayton',\n",
       " 'Garoowe',\n",
       " 'Sherman',\n",
       " 'Eisen',\n",
       " 'Moreno',\n",
       " 'Whitney',\n",
       " 'Bor',\n",
       " 'Ascot',\n",
       " 'Damme',\n",
       " 'Eau',\n",
       " 'Claire',\n",
       " 'Rees',\n",
       " 'Pérez',\n",
       " 'Vinh',\n",
       " 'Osório',\n",
       " 'Yao',\n",
       " 'Surrey',\n",
       " 'Dori',\n",
       " 'Sérres',\n",
       " 'Kamal',\n",
       " 'Denton',\n",
       " 'McHenry',\n",
       " 'Kearns',\n",
       " 'Grove',\n",
       " 'Gönen',\n",
       " 'Hāla',\n",
       " 'Sano',\n",
       " 'Marina',\n",
       " 'Alice',\n",
       " 'Wylie',\n",
       " 'Sokhumi',\n",
       " 'Moyo',\n",
       " 'Zion',\n",
       " 'Ramon',\n",
       " 'Abha',\n",
       " 'Clive',\n",
       " 'Baku',\n",
       " 'Oliveira',\n",
       " 'Saint-Pierre-des-Corps',\n",
       " 'Bentley',\n",
       " 'Casa',\n",
       " 'Grande',\n",
       " 'Amato',\n",
       " 'Garner',\n",
       " 'Kearney',\n",
       " 'Everett',\n",
       " 'Woodburn',\n",
       " 'Bañga',\n",
       " 'Florin',\n",
       " 'Tolga',\n",
       " 'Johnson',\n",
       " 'City',\n",
       " 'Sakura',\n",
       " 'Santana',\n",
       " 'Dalton',\n",
       " 'Pushkin',\n",
       " 'Quevedo',\n",
       " 'Orange',\n",
       " 'Moss',\n",
       " 'Adler',\n",
       " 'Buchanan',\n",
       " 'Rubio',\n",
       " 'Tooele',\n",
       " 'Dickinson',\n",
       " 'Layton',\n",
       " 'Rama',\n",
       " 'Lafia',\n",
       " 'Radford',\n",
       " 'Henderson',\n",
       " 'Bryant',\n",
       " 'Inđija',\n",
       " 'Cutler',\n",
       " 'Pereira',\n",
       " 'Montero',\n",
       " 'Newberg',\n",
       " 'Staines',\n",
       " 'Bender',\n",
       " 'Baní',\n",
       " 'Kirkland',\n",
       " 'Frederick',\n",
       " 'Dixon',\n",
       " 'Mason',\n",
       " 'Sơn',\n",
       " 'Pout',\n",
       " 'Campbell',\n",
       " 'Best',\n",
       " 'Man',\n",
       " 'Ende',\n",
       " 'Sofia',\n",
       " 'Rogers',\n",
       " 'Pace',\n",
       " 'Normal',\n",
       " 'Rho',\n",
       " 'Tame',\n",
       " 'Nokia',\n",
       " 'Enterprise']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_these_also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_these_words.extend(delete_these_also)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_these_words = list(dict.fromkeys(delete_these_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "902"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(delete_these_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUpperAndLowerCase(string):\n",
    "    temp_list = [string.lower(), string.upper(), string.title()]\n",
    "    with_permutations = []\n",
    "    for i in range(0,len(temp_list)):\n",
    "        with_permutations.append(temp_list[i])\n",
    "        with_permutations.append(temp_list[i]+',')\n",
    "        with_permutations.append(temp_list[i]+':')\n",
    "        with_permutations.append(temp_list[i]+'-')\n",
    "        with_permutations.append(temp_list[i]+'—')\n",
    "    return(with_permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_member(a, b): \n",
    "    a_set = set(a) \n",
    "    b_set = set(b) \n",
    "  \n",
    "    if (a_set & b_set): \n",
    "        return(list(a_set & b_set))\n",
    "    else: \n",
    "        #print(\"No common elements\")  \n",
    "        return([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get unique values \n",
    "def unique(list1): \n",
    "    x = np.array(list1) \n",
    "    return(np.unique(x)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort_Tuple(tup):  \n",
    "      \n",
    "    # getting length of list of tuples \n",
    "    lst = len(tup)  \n",
    "    for i in range(0, lst):  \n",
    "          \n",
    "        for j in range(0, lst-i-1):  \n",
    "            if (tup[j][1] > tup[j + 1][1]):  \n",
    "                temp = tup[j]  \n",
    "                tup[j]= tup[j + 1]  \n",
    "                tup[j + 1]= temp  \n",
    "    return tup  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_india = pd.read_excel('dependencies/20200705-Fuat-India coordinates8.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "districts_india = []\n",
    "cities_india = []\n",
    "states_india = []\n",
    "for i in range(0,len(df_india)):\n",
    "    districts_india.append(df_india['District'][i])\n",
    "    cities_india.append(df_india['City'][i])\n",
    "    states_india.append(df_india['State'][i])\n",
    "    \n",
    "#cities_india_unique = unique(cities_india)\n",
    "#districts_india_unique = unique(districts_india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_india = np.concatenate((districts_india, cities_india, states_india), axis=0)\n",
    "combined_india = list(combined_india)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_india.append('Indian')\n",
    "indian_state_names = [\"Andhra Pradesh\",\"Arunachal Pradesh \",\"Assam\",\"Bihar\",\"Chhattisgarh\",\"Goa\",\"Gujarat\",\"Haryana\",\"Himachal Pradesh\",\"Jammu and Kashmir\",\"Jharkhand\",\"Karnataka\",\"Kerala\",\"Madhya Pradesh\",\"Maharashtra\",\"Manipur\",\"Meghalaya\",\"Mizoram\",\"Nagaland\",\"Odisha\",\"Punjab\",\"Rajasthan\",\"Sikkim\",\"Tamil Nadu\",\"Telangana\",\"Tripura\",\"Uttar Pradesh\",\"Uttarakhand\",\"West Bengal\",\"Andaman and Nicobar Islands\",\"Chandigarh\",\"Dadra and Nagar Haveli\",\"Daman and Diu\",\"Lakshadweep\",\"National Capital Territory of Delhi\",\"Puducherry\"]\n",
    "for i in range(0, len(indian_state_names)):    \n",
    "    combined_india.append(indian_state_names[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_india.index('Along')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del combined_india[148]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cities_india = {}\n",
    "\n",
    "for i in range(0,len(combined_india)):\n",
    "    combined_cities_india[combined_india[i]] = createUpperAndLowerCase(combined_india[i])\n",
    "\n",
    "#combined_cities_india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cities_india['Along'] = ['ALONG', 'Along']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cities_india['West'] = []\n",
    "combined_cities_india['Rani'] = []\n",
    "combined_cities_india['Anju'] = []\n",
    "combined_cities_india['Un'] = []\n",
    "combined_cities_india['Bali'] = []\n",
    "combined_cities_india['Ron'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_cities_india['Bid'] = []\n",
    "#combined_cities_india['Punjab'] = []\n",
    "combined_cities_india['Pen'] = []\n",
    "for i in range(0,len(delete_these_words)):\n",
    "    combined_cities_india[delete_these_words[i]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_unique_india = np.concatenate((districts_india_unique, cities_india_unique), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nunique_cities_india = {}\\nfor i in range(0,len(combined_unique_india)):\\n    unique_cities_india[combined_unique_india[i]] = createUpperAndLowerCase(combined_unique_india[i])\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "unique_cities_india = {}\n",
    "for i in range(0,len(combined_unique_india)):\n",
    "    unique_cities_india[combined_unique_india[i]] = createUpperAndLowerCase(combined_unique_india[i])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique_cities_india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addCity1(city_list, countrycode, special):\n",
    "    var_countryname = 'combined_cities_' + str(countrycode).lower()\n",
    "    #print(var_countryname)\n",
    "    city_dict = {}\n",
    "    if special==0:\n",
    "        for i in range(0,len(city_list)):\n",
    "            city_dict[city_list[i]] = createUpperAndLowerCase(city_list[i])\n",
    "    \n",
    "    if special==1:\n",
    "        for i in range(0,len(city_list)):\n",
    "            city_dict[city_list[i]] = [city_list[i]]\n",
    "\n",
    "    var_countryname = city_dict\n",
    "    \n",
    "    #print(var_countryname)\n",
    "    \n",
    "    var_lookupcountry = 'lookup_districts_' + str(countrycode).lower()\n",
    "    var_lookupcountry = LookupData(\n",
    "        name= str(countrycode).lower() + \"_cities\",\n",
    "        data=var_countryname\n",
    "    )\n",
    "    \n",
    "    geotext.add(var_lookupcountry, update=True)\n",
    "    \n",
    "    for city in city_list:\n",
    "        delete_these_words.append(city.title())\n",
    "        try:\n",
    "            combined_cities_india[city.title()] = []\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('CA', 1)])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GeoText2('Cornwall').country_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "plural_nationalities = pd.read_excel('dependencies/plural nationalities8.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlural(plural_name):\n",
    "    try:\n",
    "        #temp_plural_without_s = list(plural_nationalities.loc[plural_nationalities['country_code']==country_code]['plural_country'])[0]\n",
    "        #temp_plural = [temp_plural_without_s, temp_plural_without_s+'s', temp_plural_without_s+\"'s\"]\n",
    "        temp_plural = [plural_name, plural_name+'s', plural_name+\"'s\"]\n",
    "        return temp_plural\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pprint\\npp = pprint.PrettyPrinter(indent=4)\\n\\n\\nj = 7747\\n\\n\\npp.pprint(list_preds[j])\\nprint('\\n')\\nprint(df['pred_country_flashgeotext'][j],'\\n')\\nprint(df['pred_country_list_flashgeotext'][j],'\\n')\\nprint(df['cleaned_text'][j])\\n\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "j = 7747\n",
    "\n",
    "\n",
    "pp.pprint(list_preds[j])\n",
    "print('\\n')\n",
    "print(df['pred_country_flashgeotext'][j],'\\n')\n",
    "print(df['pred_country_list_flashgeotext'][j],'\\n')\n",
    "print(df['cleaned_text'][j])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plural_nationalities['country_code'][65] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"Florida\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Wisconsin\", \"West Virginia\", \"Wyoming\"]\n",
    "for i in range(0,len(us_state_names)):\n",
    "    us_state_names.append(us_state_names[i].upper())\n",
    "    us_state_names.append(us_state_names[i].lower())\n",
    "\n",
    "us_abbreviations = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\",\n",
    "          \"PR\",\"AS\",\"MP\",\"CZ\",\"VI\"]\n",
    "us_abbreviations2 = []\n",
    "for i in range(0, len(us_abbreviations)):\n",
    "    us_abbreviations2.append(us_abbreviations[i])\n",
    "    us_abbreviations2.append(us_abbreviations[i].title()+'.')\n",
    "    us_abbreviations2.append(us_abbreviations[i]+'.')\n",
    "    us_abbreviations2.append(us_abbreviations[i]+',')\n",
    "    us_abbreviations2.append(us_abbreviations[i].title()+',')\n",
    "    us_abbreviations2.append(us_abbreviations[i][0]+'.'+us_abbreviations[i][1]+'.')\n",
    "    us_abbreviations2.append(us_abbreviations[i][0]+'.'+us_abbreviations[i][1].lower()+'.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "can_province_names = { 'AB': 'Alberta', 'BC': 'British Columbia', 'MB': 'Manitoba', 'NB': 'New Brunswick', 'NL': 'Newfoundland and Labrador', 'NS': 'Nova Scotia', 'NT': 'Northwest Territories', 'NU': 'Nunavut', 'ON': 'Ontario', 'PE': 'Prince Edward Island', 'QC': 'Quebec', 'SK': 'Saskatchewan', 'YT': 'Yukon' }\n",
    "can_abbreviations = list(can_province_names.keys())\n",
    "can_abbreviations2 = []\n",
    "for i in range(0, len(can_abbreviations)):\n",
    "    can_abbreviations2.append(can_abbreviations[i])\n",
    "    can_abbreviations2.append(can_abbreviations[i].title()+'.')\n",
    "    can_abbreviations2.append(can_abbreviations[i]+'.')\n",
    "    can_abbreviations2.append(can_abbreviations[i]+',')\n",
    "    can_abbreviations2.append(can_abbreviations[i].title()+',')\n",
    "    can_abbreviations2.append(can_abbreviations[i][0]+'.'+can_abbreviations[i][1]+'.')\n",
    "    can_abbreviations2.append(can_abbreviations[i][0]+'.'+can_abbreviations[i][1].lower()+'.')\n",
    "    \n",
    "can_provinces = list(can_province_names.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "can_abbreviations2.remove('On,')\n",
    "can_abbreviations2.remove('On.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alberta',\n",
       " 'British Columbia',\n",
       " 'Manitoba',\n",
       " 'New Brunswick',\n",
       " 'Newfoundland and Labrador',\n",
       " 'Nova Scotia',\n",
       " 'Northwest Territories',\n",
       " 'Nunavut',\n",
       " 'Ontario',\n",
       " 'Prince Edward Island',\n",
       " 'Quebec',\n",
       " 'Saskatchewan',\n",
       " 'Yukon']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_trad_abbr = pd.read_excel('dependencies/us traditional abbreviations8.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "us_trad_abbr_list = []\n",
    "for i in range(0,len(us_trad_abbr['abb1'])):\n",
    "    if str(list(us_trad_abbr['abb1'])[i]) != 'nan':\n",
    "        us_trad_abbr_list.append(list(us_trad_abbr['abb1'])[i])\n",
    "\n",
    "for i in range(0,len(us_trad_abbr['abb2'])):\n",
    "    if str(list(us_trad_abbr['abb2'])[i]) != 'nan':\n",
    "        us_trad_abbr_list.append(list(us_trad_abbr['abb2'])[i])\n",
    "\n",
    "for i in range(0,len(us_trad_abbr['abb3'])):\n",
    "    if str(list(us_trad_abbr['abb3'])[i]) != 'nan':\n",
    "        us_trad_abbr_list.append(list(us_trad_abbr['abb3'])[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ala.',\n",
       " 'Alaska',\n",
       " 'Ariz.',\n",
       " 'Ark.',\n",
       " 'Calif.',\n",
       " 'Colo.',\n",
       " 'Conn.',\n",
       " 'Del.',\n",
       " 'Fla.',\n",
       " 'Ga.',\n",
       " 'Idaho',\n",
       " 'Ill.',\n",
       " 'Ind.',\n",
       " 'Iowa',\n",
       " 'Kans.',\n",
       " 'Ky.',\n",
       " 'La.',\n",
       " 'Md.',\n",
       " 'Mass.',\n",
       " 'Mich.',\n",
       " 'Minn.',\n",
       " 'Miss.',\n",
       " 'Mo.',\n",
       " 'Mont.',\n",
       " 'Nebr.',\n",
       " 'Nev.',\n",
       " 'N.H.',\n",
       " 'N.J.',\n",
       " 'N. Mex.',\n",
       " 'N.Y.',\n",
       " 'N.C.',\n",
       " 'N. Dak.',\n",
       " 'Okla.',\n",
       " 'Oreg.',\n",
       " 'Pa.',\n",
       " 'R.I.',\n",
       " 'S.C.',\n",
       " 'S. Dak.',\n",
       " 'Tenn.',\n",
       " 'Tex.',\n",
       " 'Vt.',\n",
       " 'Va.',\n",
       " 'Wash.',\n",
       " 'W. Va.',\n",
       " 'Wis.',\n",
       " 'Wyo.',\n",
       " 'Cal.',\n",
       " 'Col.',\n",
       " 'Flor.',\n",
       " 'H.I.',\n",
       " 'Ida.',\n",
       " 'Ia.',\n",
       " 'Kan.',\n",
       " 'Ken.',\n",
       " 'Me.',\n",
       " 'M.N.',\n",
       " 'Neb.',\n",
       " 'N.M.',\n",
       " 'Ore.',\n",
       " 'Penn.',\n",
       " 'Wisc.',\n",
       " 'Id.',\n",
       " 'Kent.',\n",
       " 'MN',\n",
       " 'New M.',\n",
       " 'Penna.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_trad_abbr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_abbreviations2.extend(us_trad_abbr_list)\n",
    "us_state_names.extend(us_abbreviations2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_names.remove('Ms.')\n",
    "us_state_names.remove('Me.')\n",
    "us_state_names.remove('Co.')\n",
    "us_state_names.remove('Mt.')\n",
    "us_state_names.remove('Oh,')\n",
    "us_state_names.remove('Me,')\n",
    "us_state_names.remove('Ok,')\n",
    "us_state_names.remove('Ok.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us_state_names.extend(us_trad_abbr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#us_state_names\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_countries = ['IT','JM','GD','CL','MV','AG','CR','TT','LR','TO','CH','PE','BO','BG','TD','HT','PW','PA','FM','IE','CA','PR','NL','NR','AZ','SC','LK','MD','BN','GY','MM']\n",
    "missing_countries_names = {'IT': 'Italy', 'JM': 'Jamaica', 'GD': 'Grenada', 'CL': 'Chile', 'MV': 'Maldives', 'AG': 'Antigua and Barbuda', 'CR': 'Costa Rica', 'TT': 'Trinidad and Tobago', 'LR': 'Liberia', 'TO': 'Tonga', 'CH': 'Switzerland', 'PE': 'Peru', 'BO': 'Bolivia', 'BG': 'Bulgaria', 'TD': 'Chad', 'HT': 'Haiti', 'PW': 'Palau', 'PA': 'Panama', 'FM': 'Federated States of Micronesia', 'IE': 'Republic of Ireland', 'CA': 'Canada', 'PR': 'Puerto Rico', 'NL': 'Kingdom of the Netherlands', 'NR': 'Nauru', 'AZ': 'Azerbaijan', 'SC': 'Seychelles', 'LK': 'Sri Lanka', 'MD': 'Moldova', 'BN': 'Brunei Darussalam', 'GY': 'Guyana', 'MM': 'Myanmar'}\n",
    "missing_countries_capitals = {'IT': 'Rome', 'JM': 'Kingston', 'GD': \"St. George's\", 'CL': 'Santiago', 'MV': 'MalÃ©', 'AG': \"St. John's\", 'CR': 'San Jose', 'TT': 'Port of Spain', 'LR': 'Monrovia', 'TO': \"Nuku'alofa\", 'CH': 'Bern', 'PE': 'Lima', 'BO': 'Sucre', 'BG': 'Sofia', 'TD': \"N'Djamena\", 'HT': 'Port-au-Prince', 'PW': 'Ngerulmud', 'PA': 'Panama City', 'FM': 'Palikir', 'IE': 'Dublin', 'CA': 'Ottawa', 'PR': 'San Juan', 'NL': 'Amsterdam', 'NR': 'Yaren', 'AZ': 'Baku', 'SC': 'Victoria, Seychelles', 'LK': 'Sri Jayewardenepura Kotte', 'MD': 'Chisnau', 'BN': 'Bandar Seri Begawan', 'GY': 'Georgetown', 'MM': 'Naypyidaw'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IT': 'Rome',\n",
       " 'JM': 'Kingston',\n",
       " 'GD': \"St. George's\",\n",
       " 'CL': 'Santiago',\n",
       " 'MV': 'MalÃ©',\n",
       " 'AG': \"St. John's\",\n",
       " 'CR': 'San Jose',\n",
       " 'TT': 'Port of Spain',\n",
       " 'LR': 'Monrovia',\n",
       " 'TO': \"Nuku'alofa\",\n",
       " 'CH': 'Bern',\n",
       " 'PE': 'Lima',\n",
       " 'BO': 'Sucre',\n",
       " 'BG': 'Sofia',\n",
       " 'TD': \"N'Djamena\",\n",
       " 'HT': 'Port-au-Prince',\n",
       " 'PW': 'Ngerulmud',\n",
       " 'PA': 'Panama City',\n",
       " 'FM': 'Palikir',\n",
       " 'IE': 'Dublin',\n",
       " 'CA': 'Ottawa',\n",
       " 'PR': 'San Juan',\n",
       " 'NL': 'Amsterdam',\n",
       " 'NR': 'Yaren',\n",
       " 'AZ': 'Baku',\n",
       " 'SC': 'Victoria, Seychelles',\n",
       " 'LK': 'Sri Jayewardenepura Kotte',\n",
       " 'MD': 'Chisnau',\n",
       " 'BN': 'Bandar Seri Begawan',\n",
       " 'GY': 'Georgetown',\n",
       " 'MM': 'Naypyidaw'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_countries_capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:43:40.932 | DEBUG    | flashgeotext.lookup:add:194 - cities added to pool\n",
      "2020-08-02 22:43:40.940 | DEBUG    | flashgeotext.lookup:add:194 - countries added to pool\n",
      "2020-08-02 22:43:40.941 | DEBUG    | flashgeotext.lookup:_add_demo_data:225 - demo data loaded for: ['cities', 'countries']\n",
      "2020-08-02 22:43:40.951 | DEBUG    | flashgeotext.lookup:add:194 - ag17_cities added to pool\n",
      "2020-08-02 22:43:40.953 | DEBUG    | flashgeotext.lookup:add:194 - gd17_cities added to pool\n",
      "2020-08-02 22:43:40.955 | DEBUG    | flashgeotext.lookup:add:194 - tt17_cities added to pool\n",
      "2020-08-02 22:43:40.957 | DEBUG    | flashgeotext.lookup:add:194 - mv17_cities added to pool\n",
      "2020-08-02 22:43:40.958 | DEBUG    | flashgeotext.lookup:add:194 - to17_cities added to pool\n",
      "2020-08-02 22:43:40.960 | DEBUG    | flashgeotext.lookup:add:194 - in17_cities added to pool\n",
      "2020-08-02 22:43:40.963 | DEBUG    | flashgeotext.lookup:add:194 - in18_cities added to pool\n",
      "2020-08-02 22:43:40.965 | DEBUG    | flashgeotext.lookup:add:194 - in19_cities added to pool\n",
      "2020-08-02 22:43:40.971 | DEBUG    | flashgeotext.lookup:add:194 - aux_cities added to pool\n",
      "2020-08-02 22:43:40.974 | DEBUG    | flashgeotext.lookup:add:194 - bdx_cities added to pool\n",
      "2020-08-02 22:43:40.975 | DEBUG    | flashgeotext.lookup:add:194 - grx_cities added to pool\n",
      "2020-08-02 22:43:40.977 | DEBUG    | flashgeotext.lookup:add:194 - afx_cities added to pool\n",
      "2020-08-02 22:43:40.980 | DEBUG    | flashgeotext.lookup:add:194 - frx_cities added to pool\n",
      "2020-08-02 22:43:40.982 | DEBUG    | flashgeotext.lookup:add:194 - ngx_cities added to pool\n",
      "2020-08-02 22:43:40.984 | DEBUG    | flashgeotext.lookup:add:194 - eux_cities added to pool\n",
      "2020-08-02 22:43:40.986 | DEBUG    | flashgeotext.lookup:add:194 - unx_cities added to pool\n",
      "2020-08-02 22:43:40.988 | DEBUG    | flashgeotext.lookup:add:194 - idx_cities added to pool\n",
      "2020-08-02 22:43:40.989 | DEBUG    | flashgeotext.lookup:add:194 - syx_cities added to pool\n",
      "2020-08-02 22:43:40.992 | DEBUG    | flashgeotext.lookup:add:194 - brx_cities added to pool\n",
      "2020-08-02 22:43:40.993 | DEBUG    | flashgeotext.lookup:add:194 - rux_cities added to pool\n",
      "2020-08-02 22:43:41.005 | DEBUG    | flashgeotext.lookup:add:194 - usx1_cities added to pool\n",
      "2020-08-02 22:43:41.007 | DEBUG    | flashgeotext.lookup:add:194 - usx2_cities added to pool\n",
      "2020-08-02 22:43:41.012 | DEBUG    | flashgeotext.lookup:add:194 - us11_cities added to pool\n",
      "2020-08-02 22:43:41.014 | DEBUG    | flashgeotext.lookup:add:194 - htx_cities added to pool\n",
      "2020-08-02 22:43:41.015 | DEBUG    | flashgeotext.lookup:add:194 - mlx_cities added to pool\n",
      "2020-08-02 22:43:41.016 | DEBUG    | flashgeotext.lookup:add:194 - mzx_cities added to pool\n",
      "2020-08-02 22:43:41.018 | DEBUG    | flashgeotext.lookup:add:194 - bfx_cities added to pool\n",
      "2020-08-02 22:43:41.020 | DEBUG    | flashgeotext.lookup:add:194 - pgx_cities added to pool\n",
      "2020-08-02 22:43:41.025 | DEBUG    | flashgeotext.lookup:add:194 - gbx3_cities added to pool\n",
      "2020-08-02 22:43:41.028 | DEBUG    | flashgeotext.lookup:add:194 - gbx4_cities added to pool\n",
      "2020-08-02 22:43:41.029 | DEBUG    | flashgeotext.lookup:add:194 - pax_cities added to pool\n",
      "2020-08-02 22:43:41.031 | DEBUG    | flashgeotext.lookup:add:194 - so11_cities added to pool\n",
      "2020-08-02 22:43:41.033 | DEBUG    | flashgeotext.lookup:add:194 - nz11_cities added to pool\n",
      "2020-08-02 22:43:41.035 | DEBUG    | flashgeotext.lookup:add:194 - de11_cities added to pool\n",
      "2020-08-02 22:43:41.039 | DEBUG    | flashgeotext.lookup:add:194 - it11_cities added to pool\n",
      "2020-08-02 22:43:41.044 | DEBUG    | flashgeotext.lookup:add:194 - at11_cities added to pool\n",
      "2020-08-02 22:43:41.046 | DEBUG    | flashgeotext.lookup:add:194 - sy11_cities added to pool\n",
      "2020-08-02 22:43:41.051 | DEBUG    | flashgeotext.lookup:add:194 - ye11_cities added to pool\n",
      "2020-08-02 22:43:41.054 | DEBUG    | flashgeotext.lookup:add:194 - ca11_cities added to pool\n",
      "2020-08-02 22:43:41.056 | DEBUG    | flashgeotext.lookup:add:194 - cn11_cities added to pool\n",
      "2020-08-02 22:43:41.059 | DEBUG    | flashgeotext.lookup:add:194 - ps11_cities added to pool\n",
      "2020-08-02 22:43:41.061 | DEBUG    | flashgeotext.lookup:add:194 - hu11_cities added to pool\n",
      "2020-08-02 22:43:41.063 | DEBUG    | flashgeotext.lookup:add:194 - sv11_cities added to pool\n",
      "2020-08-02 22:43:41.065 | DEBUG    | flashgeotext.lookup:add:194 - cd11_cities added to pool\n",
      "2020-08-02 22:43:41.066 | DEBUG    | flashgeotext.lookup:add:194 - cg11_cities added to pool\n",
      "2020-08-02 22:43:41.068 | DEBUG    | flashgeotext.lookup:add:194 - ug11_cities added to pool\n",
      "2020-08-02 22:43:41.071 | DEBUG    | flashgeotext.lookup:add:194 - ec11_cities added to pool\n",
      "2020-08-02 22:43:41.073 | DEBUG    | flashgeotext.lookup:add:194 - il11_cities added to pool\n",
      "2020-08-02 22:43:41.078 | DEBUG    | flashgeotext.lookup:add:194 - cy11_cities added to pool\n",
      "2020-08-02 22:43:41.080 | DEBUG    | flashgeotext.lookup:add:194 - do11_cities added to pool\n",
      "2020-08-02 22:43:41.084 | DEBUG    | flashgeotext.lookup:add:194 - th11_cities added to pool\n",
      "2020-08-02 22:43:41.086 | DEBUG    | flashgeotext.lookup:add:194 - nl12_cities added to pool\n",
      "2020-08-02 22:43:41.089 | DEBUG    | flashgeotext.lookup:add:194 - bm11_cities added to pool\n",
      "2020-08-02 22:43:41.091 | DEBUG    | flashgeotext.lookup:add:194 - kp11_cities added to pool\n",
      "2020-08-02 22:43:41.093 | DEBUG    | flashgeotext.lookup:add:194 - es11_cities added to pool\n",
      "2020-08-02 22:43:41.100 | DEBUG    | flashgeotext.lookup:add:194 - za11_cities added to pool\n",
      "2020-08-02 22:43:41.104 | DEBUG    | flashgeotext.lookup:add:194 - sc11_cities added to pool\n",
      "2020-08-02 22:43:41.107 | DEBUG    | flashgeotext.lookup:add:194 - ir11_cities added to pool\n",
      "2020-08-02 22:43:41.110 | DEBUG    | flashgeotext.lookup:add:194 - qa11_cities added to pool\n",
      "2020-08-02 22:43:41.113 | DEBUG    | flashgeotext.lookup:add:194 - ch11_cities added to pool\n",
      "2020-08-02 22:43:41.115 | DEBUG    | flashgeotext.lookup:add:194 - sx11_cities added to pool\n",
      "2020-08-02 22:43:41.117 | DEBUG    | flashgeotext.lookup:add:194 - ae11_cities added to pool\n",
      "2020-08-02 22:43:41.120 | DEBUG    | flashgeotext.lookup:add:194 - bs11_cities added to pool\n",
      "2020-08-02 22:43:41.123 | DEBUG    | flashgeotext.lookup:add:194 - vn11_cities added to pool\n",
      "2020-08-02 22:43:41.125 | DEBUG    | flashgeotext.lookup:add:194 - se11_cities added to pool\n",
      "2020-08-02 22:43:41.128 | DEBUG    | flashgeotext.lookup:add:194 - ke11_cities added to pool\n",
      "2020-08-02 22:43:41.131 | DEBUG    | flashgeotext.lookup:add:194 - bz11_cities added to pool\n",
      "2020-08-02 22:43:41.134 | DEBUG    | flashgeotext.lookup:add:194 - aq11_cities added to pool\n",
      "2020-08-02 22:43:41.136 | DEBUG    | flashgeotext.lookup:add:194 - ne11_cities added to pool\n",
      "2020-08-02 22:43:41.139 | DEBUG    | flashgeotext.lookup:add:194 - fm11_cities added to pool\n",
      "2020-08-02 22:43:41.141 | DEBUG    | flashgeotext.lookup:add:194 - jp11_cities added to pool\n",
      "2020-08-02 22:43:41.144 | DEBUG    | flashgeotext.lookup:add:194 - pt11_cities added to pool\n",
      "2020-08-02 22:43:41.146 | DEBUG    | flashgeotext.lookup:add:194 - ws_cities added to pool\n",
      "2020-08-02 22:43:41.148 | DEBUG    | flashgeotext.lookup:add:194 - ly11_cities added to pool\n",
      "2020-08-02 22:43:41.150 | DEBUG    | flashgeotext.lookup:add:194 - tr11_cities added to pool\n",
      "2020-08-02 22:43:41.152 | DEBUG    | flashgeotext.lookup:add:194 - fj11_cities added to pool\n",
      "2020-08-02 22:43:41.156 | DEBUG    | flashgeotext.lookup:add:194 - gl11_cities added to pool\n",
      "2020-08-02 22:43:41.158 | DEBUG    | flashgeotext.lookup:add:194 - tj11_cities added to pool\n",
      "2020-08-02 22:43:41.160 | DEBUG    | flashgeotext.lookup:add:194 - uz11_cities added to pool\n",
      "2020-08-02 22:43:41.163 | DEBUG    | flashgeotext.lookup:add:194 - sb11_cities added to pool\n",
      "2020-08-02 22:43:41.165 | DEBUG    | flashgeotext.lookup:add:194 - ua11_cities added to pool\n",
      "2020-08-02 22:43:41.167 | DEBUG    | flashgeotext.lookup:add:194 - hk12_cities added to pool\n",
      "2020-08-02 22:43:41.169 | DEBUG    | flashgeotext.lookup:add:194 - mt11_cities added to pool\n",
      "2020-08-02 22:43:41.171 | DEBUG    | flashgeotext.lookup:add:194 - nax11_cities added to pool\n",
      "2020-08-02 22:43:41.173 | DEBUG    | flashgeotext.lookup:add:194 - ba11_cities added to pool\n",
      "2020-08-02 22:43:41.175 | DEBUG    | flashgeotext.lookup:add:194 - dm11_cities added to pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:43:41.177 | DEBUG    | flashgeotext.lookup:add:194 - tg11_cities added to pool\n",
      "2020-08-02 22:43:41.179 | DEBUG    | flashgeotext.lookup:add:194 - va11_cities added to pool\n",
      "2020-08-02 22:43:41.182 | DEBUG    | flashgeotext.lookup:add:194 - gh11_cities added to pool\n",
      "2020-08-02 22:43:41.186 | DEBUG    | flashgeotext.lookup:add:194 - cv11_cities added to pool\n",
      "2020-08-02 22:43:41.187 | DEBUG    | flashgeotext.lookup:add:194 - lk14_cities added to pool\n",
      "2020-08-02 22:43:41.190 | DEBUG    | flashgeotext.lookup:add:194 - mx14_cities added to pool\n",
      "2020-08-02 22:43:41.191 | DEBUG    | flashgeotext.lookup:add:194 - sl14_cities added to pool\n",
      "2020-08-02 22:43:41.194 | DEBUG    | flashgeotext.lookup:add:194 - bj14_cities added to pool\n",
      "2020-08-02 22:43:41.196 | DEBUG    | flashgeotext.lookup:add:194 - cr14_cities added to pool\n",
      "2020-08-02 22:43:41.197 | DEBUG    | flashgeotext.lookup:add:194 - gd14_cities added to pool\n",
      "2020-08-02 22:43:41.199 | DEBUG    | flashgeotext.lookup:add:194 - md14_cities added to pool\n",
      "2020-08-02 22:43:41.200 | DEBUG    | flashgeotext.lookup:add:194 - sc14_cities added to pool\n",
      "2020-08-02 22:43:41.201 | DEBUG    | flashgeotext.lookup:add:194 - ss14_cities added to pool\n",
      "2020-08-02 22:43:41.202 | DEBUG    | flashgeotext.lookup:add:194 - lk15_cities added to pool\n",
      "2020-08-02 22:43:41.203 | DEBUG    | flashgeotext.lookup:add:194 - my15_cities added to pool\n",
      "2020-08-02 22:43:41.205 | DEBUG    | flashgeotext.lookup:add:194 - ao21_cities added to pool\n",
      "2020-08-02 22:43:41.206 | DEBUG    | flashgeotext.lookup:add:194 - ag21_cities added to pool\n",
      "2020-08-02 22:43:41.207 | DEBUG    | flashgeotext.lookup:add:194 - ba21_cities added to pool\n",
      "2020-08-02 22:43:41.208 | DEBUG    | flashgeotext.lookup:add:194 - gq21_cities added to pool\n",
      "2020-08-02 22:43:41.209 | DEBUG    | flashgeotext.lookup:add:194 - er21_cities added to pool\n",
      "2020-08-02 22:43:41.210 | DEBUG    | flashgeotext.lookup:add:194 - gm21_cities added to pool\n",
      "2020-08-02 22:43:41.211 | DEBUG    | flashgeotext.lookup:add:194 - ni21_cities added to pool\n",
      "2020-08-02 22:43:41.212 | DEBUG    | flashgeotext.lookup:add:194 - gn21_cities added to pool\n",
      "2020-08-02 22:43:41.213 | DEBUG    | flashgeotext.lookup:add:194 - hn21_cities added to pool\n",
      "2020-08-02 22:43:41.214 | DEBUG    | flashgeotext.lookup:add:194 - li21_cities added to pool\n",
      "2020-08-02 22:43:41.215 | DEBUG    | flashgeotext.lookup:add:194 - mk21_cities added to pool\n",
      "2020-08-02 22:43:41.216 | DEBUG    | flashgeotext.lookup:add:194 - mh21_cities added to pool\n",
      "2020-08-02 22:43:41.217 | DEBUG    | flashgeotext.lookup:add:194 - mu21_cities added to pool\n",
      "2020-08-02 22:43:41.218 | DEBUG    | flashgeotext.lookup:add:194 - fm21_cities added to pool\n",
      "2020-08-02 22:43:41.218 | DEBUG    | flashgeotext.lookup:add:194 - mn21_cities added to pool\n",
      "2020-08-02 22:43:41.219 | DEBUG    | flashgeotext.lookup:add:194 - ni21_cities added to pool\n",
      "2020-08-02 22:43:41.220 | DEBUG    | flashgeotext.lookup:add:194 - ps21_cities added to pool\n",
      "2020-08-02 22:43:41.222 | DEBUG    | flashgeotext.lookup:add:194 - py21_cities added to pool\n",
      "2020-08-02 22:43:41.222 | DEBUG    | flashgeotext.lookup:add:194 - sn21_cities added to pool\n",
      "2020-08-02 22:43:41.223 | DEBUG    | flashgeotext.lookup:add:194 - sz21_cities added to pool\n",
      "2020-08-02 22:43:41.224 | DEBUG    | flashgeotext.lookup:add:194 - tm21_cities added to pool\n",
      "2020-08-02 22:43:41.225 | DEBUG    | flashgeotext.lookup:add:194 - uy21_cities added to pool\n",
      "2020-08-02 22:43:41.226 | DEBUG    | flashgeotext.lookup:add:194 - kn21_cities added to pool\n",
      "2020-08-02 22:43:41.227 | DEBUG    | flashgeotext.lookup:add:194 - lc21_cities added to pool\n",
      "2020-08-02 22:43:41.228 | DEBUG    | flashgeotext.lookup:add:194 - vc21_cities added to pool\n",
      "2020-08-02 22:43:41.228 | DEBUG    | flashgeotext.lookup:add:194 - ss21_cities added to pool\n",
      "2020-08-02 22:43:41.229 | DEBUG    | flashgeotext.lookup:add:194 - tt21_cities added to pool\n",
      "2020-08-02 22:43:41.230 | DEBUG    | flashgeotext.lookup:add:194 - ae21_cities added to pool\n",
      "2020-08-02 22:43:41.231 | DEBUG    | flashgeotext.lookup:add:194 - gw21_cities added to pool\n",
      "2020-08-02 22:43:41.232 | DEBUG    | flashgeotext.lookup:add:194 - ge21_cities added to pool\n",
      "2020-08-02 22:43:41.233 | DEBUG    | flashgeotext.lookup:add:194 - ca21_cities added to pool\n",
      "2020-08-02 22:43:41.234 | DEBUG    | flashgeotext.lookup:add:194 - ca17_cities added to pool\n",
      "2020-08-02 22:43:41.235 | DEBUG    | flashgeotext.lookup:add:194 - pk11_cities added to pool\n",
      "2020-08-02 22:43:41.236 | DEBUG    | flashgeotext.lookup:add:194 - ca18_cities added to pool\n",
      "2020-08-02 22:43:41.237 | DEBUG    | flashgeotext.lookup:add:194 - ie11_cities added to pool\n",
      "2020-08-02 22:43:41.237 | DEBUG    | flashgeotext.lookup:add:194 - tt11_cities added to pool\n",
      "2020-08-02 22:43:41.238 | DEBUG    | flashgeotext.lookup:add:194 - hk11_cities added to pool\n",
      "2020-08-02 22:43:41.239 | DEBUG    | flashgeotext.lookup:add:194 - itxc13_cities added to pool\n",
      "2020-08-02 22:43:41.240 | DEBUG    | flashgeotext.lookup:add:194 - jmxc13_cities added to pool\n",
      "2020-08-02 22:43:41.241 | DEBUG    | flashgeotext.lookup:add:194 - gdxc13_cities added to pool\n",
      "2020-08-02 22:43:41.241 | DEBUG    | flashgeotext.lookup:add:194 - clxc13_cities added to pool\n",
      "2020-08-02 22:43:41.242 | DEBUG    | flashgeotext.lookup:add:194 - mvxc13_cities added to pool\n",
      "2020-08-02 22:43:41.243 | DEBUG    | flashgeotext.lookup:add:194 - agxc13_cities added to pool\n",
      "2020-08-02 22:43:41.244 | DEBUG    | flashgeotext.lookup:add:194 - crxc13_cities added to pool\n",
      "2020-08-02 22:43:41.245 | DEBUG    | flashgeotext.lookup:add:194 - ttxc13_cities added to pool\n",
      "2020-08-02 22:43:41.245 | DEBUG    | flashgeotext.lookup:add:194 - lrxc13_cities added to pool\n",
      "2020-08-02 22:43:41.246 | DEBUG    | flashgeotext.lookup:add:194 - toxc13_cities added to pool\n",
      "2020-08-02 22:43:41.247 | DEBUG    | flashgeotext.lookup:add:194 - chxc13_cities added to pool\n",
      "2020-08-02 22:43:41.248 | DEBUG    | flashgeotext.lookup:add:194 - pexc13_cities added to pool\n",
      "2020-08-02 22:43:41.249 | DEBUG    | flashgeotext.lookup:add:194 - boxc13_cities added to pool\n",
      "2020-08-02 22:43:41.249 | DEBUG    | flashgeotext.lookup:add:194 - bgxc13_cities added to pool\n",
      "2020-08-02 22:43:41.250 | DEBUG    | flashgeotext.lookup:add:194 - tdxc13_cities added to pool\n",
      "2020-08-02 22:43:41.251 | DEBUG    | flashgeotext.lookup:add:194 - htxc13_cities added to pool\n",
      "2020-08-02 22:43:41.252 | DEBUG    | flashgeotext.lookup:add:194 - pwxc13_cities added to pool\n",
      "2020-08-02 22:43:41.253 | DEBUG    | flashgeotext.lookup:add:194 - paxc13_cities added to pool\n",
      "2020-08-02 22:43:41.256 | DEBUG    | flashgeotext.lookup:add:194 - fmxc13_cities added to pool\n",
      "2020-08-02 22:43:41.258 | DEBUG    | flashgeotext.lookup:add:194 - iexc13_cities added to pool\n",
      "2020-08-02 22:43:41.259 | DEBUG    | flashgeotext.lookup:add:194 - caxc13_cities added to pool\n",
      "2020-08-02 22:43:41.260 | DEBUG    | flashgeotext.lookup:add:194 - prxc13_cities added to pool\n",
      "2020-08-02 22:43:41.261 | DEBUG    | flashgeotext.lookup:add:194 - nlxc13_cities added to pool\n",
      "2020-08-02 22:43:41.265 | DEBUG    | flashgeotext.lookup:add:194 - nrxc13_cities added to pool\n",
      "2020-08-02 22:43:41.268 | DEBUG    | flashgeotext.lookup:add:194 - azxc13_cities added to pool\n",
      "2020-08-02 22:43:41.269 | DEBUG    | flashgeotext.lookup:add:194 - scxc13_cities added to pool\n",
      "2020-08-02 22:43:41.272 | DEBUG    | flashgeotext.lookup:add:194 - lkxc13_cities added to pool\n",
      "2020-08-02 22:43:41.274 | DEBUG    | flashgeotext.lookup:add:194 - mdxc13_cities added to pool\n",
      "2020-08-02 22:43:41.275 | DEBUG    | flashgeotext.lookup:add:194 - bnxc13_cities added to pool\n",
      "2020-08-02 22:43:41.276 | DEBUG    | flashgeotext.lookup:add:194 - gyxc13_cities added to pool\n",
      "2020-08-02 22:43:41.277 | DEBUG    | flashgeotext.lookup:add:194 - mmxc13_cities added to pool\n",
      "2020-08-02 22:43:41.279 | DEBUG    | flashgeotext.lookup:add:194 - afyc0_cities added to pool\n",
      "2020-08-02 22:43:41.281 | DEBUG    | flashgeotext.lookup:add:194 - dzyc1_cities added to pool\n",
      "2020-08-02 22:43:41.283 | DEBUG    | flashgeotext.lookup:add:194 - aoyc2_cities added to pool\n",
      "2020-08-02 22:43:41.285 | DEBUG    | flashgeotext.lookup:add:194 - aryc3_cities added to pool\n",
      "2020-08-02 22:43:41.288 | DEBUG    | flashgeotext.lookup:add:194 - atyc4_cities added to pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:43:41.289 | DEBUG    | flashgeotext.lookup:add:194 - auyc5_cities added to pool\n",
      "2020-08-02 22:43:41.291 | DEBUG    | flashgeotext.lookup:add:194 - auyc6_cities added to pool\n",
      "2020-08-02 22:43:41.295 | DEBUG    | flashgeotext.lookup:add:194 - auyc7_cities added to pool\n",
      "2020-08-02 22:43:41.298 | DEBUG    | flashgeotext.lookup:add:194 - bdyc8_cities added to pool\n",
      "2020-08-02 22:43:41.300 | DEBUG    | flashgeotext.lookup:add:194 - byyc9_cities added to pool\n",
      "2020-08-02 22:43:41.303 | DEBUG    | flashgeotext.lookup:add:194 - beyc10_cities added to pool\n",
      "2020-08-02 22:43:41.305 | DEBUG    | flashgeotext.lookup:add:194 - boyc11_cities added to pool\n",
      "2020-08-02 22:43:41.306 | DEBUG    | flashgeotext.lookup:add:194 - bayc12_cities added to pool\n",
      "2020-08-02 22:43:41.307 | DEBUG    | flashgeotext.lookup:add:194 - bayc13_cities added to pool\n",
      "2020-08-02 22:43:41.309 | DEBUG    | flashgeotext.lookup:add:194 - bryc14_cities added to pool\n",
      "2020-08-02 22:43:41.310 | DEBUG    | flashgeotext.lookup:add:194 - gbx1yc15_cities added to pool\n",
      "2020-08-02 22:43:41.311 | DEBUG    | flashgeotext.lookup:add:194 - gbx1yc16_cities added to pool\n",
      "2020-08-02 22:43:41.312 | DEBUG    | flashgeotext.lookup:add:194 - bgyc17_cities added to pool\n",
      "2020-08-02 22:43:41.313 | DEBUG    | flashgeotext.lookup:add:194 - khyc18_cities added to pool\n",
      "2020-08-02 22:43:41.314 | DEBUG    | flashgeotext.lookup:add:194 - cmyc19_cities added to pool\n",
      "2020-08-02 22:43:41.315 | DEBUG    | flashgeotext.lookup:add:194 - cayc20_cities added to pool\n",
      "2020-08-02 22:43:41.316 | DEBUG    | flashgeotext.lookup:add:194 - cfyc21_cities added to pool\n",
      "2020-08-02 22:43:41.317 | DEBUG    | flashgeotext.lookup:add:194 - tdyc22_cities added to pool\n",
      "2020-08-02 22:43:41.319 | DEBUG    | flashgeotext.lookup:add:194 - cnyc23_cities added to pool\n",
      "2020-08-02 22:43:41.320 | DEBUG    | flashgeotext.lookup:add:194 - coyc24_cities added to pool\n",
      "2020-08-02 22:43:41.323 | DEBUG    | flashgeotext.lookup:add:194 - cryc25_cities added to pool\n",
      "2020-08-02 22:43:41.325 | DEBUG    | flashgeotext.lookup:add:194 - hryc26_cities added to pool\n",
      "2020-08-02 22:43:41.327 | DEBUG    | flashgeotext.lookup:add:194 - czyc27_cities added to pool\n",
      "2020-08-02 22:43:41.329 | DEBUG    | flashgeotext.lookup:add:194 - cdyc28_cities added to pool\n",
      "2020-08-02 22:43:41.331 | DEBUG    | flashgeotext.lookup:add:194 - dkyc29_cities added to pool\n",
      "2020-08-02 22:43:41.332 | DEBUG    | flashgeotext.lookup:add:194 - ecyc30_cities added to pool\n",
      "2020-08-02 22:43:41.333 | DEBUG    | flashgeotext.lookup:add:194 - egyc31_cities added to pool\n",
      "2020-08-02 22:43:41.334 | DEBUG    | flashgeotext.lookup:add:194 - svyc32_cities added to pool\n",
      "2020-08-02 22:43:41.336 | DEBUG    | flashgeotext.lookup:add:194 - eeyc34_cities added to pool\n",
      "2020-08-02 22:43:41.337 | DEBUG    | flashgeotext.lookup:add:194 - etyc35_cities added to pool\n",
      "2020-08-02 22:43:41.338 | DEBUG    | flashgeotext.lookup:add:194 - fiyc36_cities added to pool\n",
      "2020-08-02 22:43:41.339 | DEBUG    | flashgeotext.lookup:add:194 - fryc37_cities added to pool\n",
      "2020-08-02 22:43:41.340 | DEBUG    | flashgeotext.lookup:add:194 - deyc38_cities added to pool\n",
      "2020-08-02 22:43:41.341 | DEBUG    | flashgeotext.lookup:add:194 - ghyc39_cities added to pool\n",
      "2020-08-02 22:43:41.342 | DEBUG    | flashgeotext.lookup:add:194 - gryc40_cities added to pool\n",
      "2020-08-02 22:43:41.343 | DEBUG    | flashgeotext.lookup:add:194 - gtyc41_cities added to pool\n",
      "2020-08-02 22:43:41.344 | DEBUG    | flashgeotext.lookup:add:194 - nlyc42_cities added to pool\n",
      "2020-08-02 22:43:41.345 | DEBUG    | flashgeotext.lookup:add:194 - hnyc43_cities added to pool\n",
      "2020-08-02 22:43:41.346 | DEBUG    | flashgeotext.lookup:add:194 - huyc44_cities added to pool\n",
      "2020-08-02 22:43:41.347 | DEBUG    | flashgeotext.lookup:add:194 - isyc45_cities added to pool\n",
      "2020-08-02 22:43:41.347 | DEBUG    | flashgeotext.lookup:add:194 - inyc46_cities added to pool\n",
      "2020-08-02 22:43:41.348 | DEBUG    | flashgeotext.lookup:add:194 - idyc47_cities added to pool\n",
      "2020-08-02 22:43:41.349 | DEBUG    | flashgeotext.lookup:add:194 - iryc48_cities added to pool\n",
      "2020-08-02 22:43:41.350 | DEBUG    | flashgeotext.lookup:add:194 - iqyc49_cities added to pool\n",
      "2020-08-02 22:43:41.351 | DEBUG    | flashgeotext.lookup:add:194 - ieyc50_cities added to pool\n",
      "2020-08-02 22:43:41.352 | DEBUG    | flashgeotext.lookup:add:194 - ilyc51_cities added to pool\n",
      "2020-08-02 22:43:41.353 | DEBUG    | flashgeotext.lookup:add:194 - ityc52_cities added to pool\n",
      "2020-08-02 22:43:41.354 | DEBUG    | flashgeotext.lookup:add:194 - ciyc53_cities added to pool\n",
      "2020-08-02 22:43:41.355 | DEBUG    | flashgeotext.lookup:add:194 - jmyc54_cities added to pool\n",
      "2020-08-02 22:43:41.356 | DEBUG    | flashgeotext.lookup:add:194 - jpyc55_cities added to pool\n",
      "2020-08-02 22:43:41.357 | DEBUG    | flashgeotext.lookup:add:194 - joyc56_cities added to pool\n",
      "2020-08-02 22:43:41.358 | DEBUG    | flashgeotext.lookup:add:194 - kzyc57_cities added to pool\n",
      "2020-08-02 22:43:41.359 | DEBUG    | flashgeotext.lookup:add:194 - keyc58_cities added to pool\n",
      "2020-08-02 22:43:41.360 | DEBUG    | flashgeotext.lookup:add:194 - layc59_cities added to pool\n",
      "2020-08-02 22:43:41.361 | DEBUG    | flashgeotext.lookup:add:194 - lvyc60_cities added to pool\n",
      "2020-08-02 22:43:41.362 | DEBUG    | flashgeotext.lookup:add:194 - lyyc61_cities added to pool\n",
      "2020-08-02 22:43:41.363 | DEBUG    | flashgeotext.lookup:add:194 - ltyc62_cities added to pool\n",
      "2020-08-02 22:43:41.364 | DEBUG    | flashgeotext.lookup:add:194 - mgyc63_cities added to pool\n",
      "2020-08-02 22:43:41.364 | DEBUG    | flashgeotext.lookup:add:194 - myyc64_cities added to pool\n",
      "2020-08-02 22:43:41.365 | DEBUG    | flashgeotext.lookup:add:194 - mlyc65_cities added to pool\n",
      "2020-08-02 22:43:41.366 | DEBUG    | flashgeotext.lookup:add:194 - mryc66_cities added to pool\n",
      "2020-08-02 22:43:41.367 | DEBUG    | flashgeotext.lookup:add:194 - mxyc67_cities added to pool\n",
      "2020-08-02 22:43:41.368 | DEBUG    | flashgeotext.lookup:add:194 - mayc68_cities added to pool\n",
      "2020-08-02 22:43:41.369 | DEBUG    | flashgeotext.lookup:add:194 - nzyc70_cities added to pool\n",
      "2020-08-02 22:43:41.370 | DEBUG    | flashgeotext.lookup:add:194 - niyc71_cities added to pool\n",
      "2020-08-02 22:43:41.370 | DEBUG    | flashgeotext.lookup:add:194 - neyc72_cities added to pool\n",
      "2020-08-02 22:43:41.371 | DEBUG    | flashgeotext.lookup:add:194 - ngyc73_cities added to pool\n",
      "2020-08-02 22:43:41.372 | DEBUG    | flashgeotext.lookup:add:194 - noyc74_cities added to pool\n",
      "2020-08-02 22:43:41.373 | DEBUG    | flashgeotext.lookup:add:194 - omyc75_cities added to pool\n",
      "2020-08-02 22:43:41.373 | DEBUG    | flashgeotext.lookup:add:194 - pkyc76_cities added to pool\n",
      "2020-08-02 22:43:41.374 | DEBUG    | flashgeotext.lookup:add:194 - payc77_cities added to pool\n",
      "2020-08-02 22:43:41.375 | DEBUG    | flashgeotext.lookup:add:194 - pyyc78_cities added to pool\n",
      "2020-08-02 22:43:41.376 | DEBUG    | flashgeotext.lookup:add:194 - peyc79_cities added to pool\n",
      "2020-08-02 22:43:41.377 | DEBUG    | flashgeotext.lookup:add:194 - phyc80_cities added to pool\n",
      "2020-08-02 22:43:41.378 | DEBUG    | flashgeotext.lookup:add:194 - phyc81_cities added to pool\n",
      "2020-08-02 22:43:41.379 | DEBUG    | flashgeotext.lookup:add:194 - plyc82_cities added to pool\n",
      "2020-08-02 22:43:41.380 | DEBUG    | flashgeotext.lookup:add:194 - ptyc83_cities added to pool\n",
      "2020-08-02 22:43:41.381 | DEBUG    | flashgeotext.lookup:add:194 - cgyc84_cities added to pool\n",
      "2020-08-02 22:43:41.382 | DEBUG    | flashgeotext.lookup:add:194 - royc85_cities added to pool\n",
      "2020-08-02 22:43:41.383 | DEBUG    | flashgeotext.lookup:add:194 - ruyc86_cities added to pool\n",
      "2020-08-02 22:43:41.384 | DEBUG    | flashgeotext.lookup:add:194 - sayc87_cities added to pool\n",
      "2020-08-02 22:43:41.385 | DEBUG    | flashgeotext.lookup:add:194 - gbyc88_cities added to pool\n",
      "2020-08-02 22:43:41.387 | DEBUG    | flashgeotext.lookup:add:194 - snyc89_cities added to pool\n",
      "2020-08-02 22:43:41.387 | DEBUG    | flashgeotext.lookup:add:194 - rsyc90_cities added to pool\n",
      "2020-08-02 22:43:41.389 | DEBUG    | flashgeotext.lookup:add:194 - sgyc91_cities added to pool\n",
      "2020-08-02 22:43:41.390 | DEBUG    | flashgeotext.lookup:add:194 - skyc92_cities added to pool\n",
      "2020-08-02 22:43:41.392 | DEBUG    | flashgeotext.lookup:add:194 - soyc93_cities added to pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:43:41.393 | DEBUG    | flashgeotext.lookup:add:194 - zayc94_cities added to pool\n",
      "2020-08-02 22:43:41.394 | DEBUG    | flashgeotext.lookup:add:194 - zayc95_cities added to pool\n",
      "2020-08-02 22:43:41.395 | DEBUG    | flashgeotext.lookup:add:194 - esyc96_cities added to pool\n",
      "2020-08-02 22:43:41.397 | DEBUG    | flashgeotext.lookup:add:194 - sdyc97_cities added to pool\n",
      "2020-08-02 22:43:41.399 | DEBUG    | flashgeotext.lookup:add:194 - seyc98_cities added to pool\n",
      "2020-08-02 22:43:41.402 | DEBUG    | flashgeotext.lookup:add:194 - chyc99_cities added to pool\n",
      "2020-08-02 22:43:41.776 | DEBUG    | flashgeotext.lookup:add:194 - syyc100_cities added to pool\n",
      "2020-08-02 22:43:41.778 | DEBUG    | flashgeotext.lookup:add:194 - thyc101_cities added to pool\n",
      "2020-08-02 22:43:41.780 | DEBUG    | flashgeotext.lookup:add:194 - tnyc102_cities added to pool\n",
      "2020-08-02 22:43:41.781 | DEBUG    | flashgeotext.lookup:add:194 - tryc103_cities added to pool\n",
      "2020-08-02 22:43:41.782 | DEBUG    | flashgeotext.lookup:add:194 - tmyc104_cities added to pool\n",
      "2020-08-02 22:43:41.783 | DEBUG    | flashgeotext.lookup:add:194 - uayc105_cities added to pool\n",
      "2020-08-02 22:43:41.784 | DEBUG    | flashgeotext.lookup:add:194 - aeyc106_cities added to pool\n",
      "2020-08-02 22:43:41.785 | DEBUG    | flashgeotext.lookup:add:194 - usyc107_cities added to pool\n",
      "2020-08-02 22:43:41.786 | DEBUG    | flashgeotext.lookup:add:194 - uyyc108_cities added to pool\n",
      "2020-08-02 22:43:41.787 | DEBUG    | flashgeotext.lookup:add:194 - vnyc109_cities added to pool\n",
      "2020-08-02 22:43:41.788 | DEBUG    | flashgeotext.lookup:add:194 - gbyc110_cities added to pool\n",
      "2020-08-02 22:43:41.790 | DEBUG    | flashgeotext.lookup:add:194 - zmyc111_cities added to pool\n",
      "2020-08-02 22:43:41.791 | DEBUG    | flashgeotext.lookup:add:194 - zwyc112_cities added to pool\n",
      "2020-08-02 22:43:41.792 | DEBUG    | flashgeotext.lookup:add:194 - psyc113_cities added to pool\n",
      "2020-08-02 22:43:41.793 | DEBUG    | flashgeotext.lookup:add:194 - npyc114_cities added to pool\n",
      "2020-08-02 22:43:41.794 | DEBUG    | flashgeotext.lookup:add:194 - soxyc115_cities added to pool\n",
      "2020-08-02 22:43:41.795 | DEBUG    | flashgeotext.lookup:add:194 - htyc116_cities added to pool\n",
      "2020-08-02 22:43:41.796 | DEBUG    | flashgeotext.lookup:add:194 - soxyc117_cities added to pool\n",
      "2020-08-02 22:43:41.797 | DEBUG    | flashgeotext.lookup:add:194 - gbx2yc118_cities added to pool\n",
      "2020-08-02 22:43:41.798 | DEBUG    | flashgeotext.lookup:add:194 - ve1yc119_cities added to pool\n",
      "2020-08-02 22:43:41.799 | DEBUG    | flashgeotext.lookup:add:194 - kpyc120_cities added to pool\n",
      "2020-08-02 22:43:41.801 | DEBUG    | flashgeotext.lookup:add:194 - kryc121_cities added to pool\n",
      "2020-08-02 22:43:41.802 | DEBUG    | flashgeotext.lookup:add:194 - kryc122_cities added to pool\n",
      "2020-08-02 22:43:41.803 | DEBUG    | flashgeotext.lookup:add:194 - kryc123_cities added to pool\n",
      "2020-08-02 22:43:41.804 | DEBUG    | flashgeotext.lookup:add:194 - kpyc124_cities added to pool\n",
      "2020-08-02 22:43:41.805 | DEBUG    | flashgeotext.lookup:add:194 - lbyc125_cities added to pool\n",
      "2020-08-02 22:43:41.806 | DEBUG    | flashgeotext.lookup:add:194 - doyc126_cities added to pool\n",
      "2020-08-02 22:43:41.807 | DEBUG    | flashgeotext.lookup:add:194 - wsyc127_cities added to pool\n",
      "2020-08-02 22:43:41.808 | DEBUG    | flashgeotext.lookup:add:194 - alyc128_cities added to pool\n",
      "2020-08-02 22:43:41.809 | DEBUG    | flashgeotext.lookup:add:194 - asyc129_cities added to pool\n",
      "2020-08-02 22:43:41.810 | DEBUG    | flashgeotext.lookup:add:194 - adyc130_cities added to pool\n",
      "2020-08-02 22:43:41.811 | DEBUG    | flashgeotext.lookup:add:194 - aiyc131_cities added to pool\n",
      "2020-08-02 22:43:41.812 | DEBUG    | flashgeotext.lookup:add:194 - aqyc132_cities added to pool\n",
      "2020-08-02 22:43:41.813 | DEBUG    | flashgeotext.lookup:add:194 - agyc133_cities added to pool\n",
      "2020-08-02 22:43:41.813 | DEBUG    | flashgeotext.lookup:add:194 - amyc134_cities added to pool\n",
      "2020-08-02 22:43:41.814 | DEBUG    | flashgeotext.lookup:add:194 - awyc135_cities added to pool\n",
      "2020-08-02 22:43:41.815 | DEBUG    | flashgeotext.lookup:add:194 - azyc136_cities added to pool\n",
      "2020-08-02 22:43:41.816 | DEBUG    | flashgeotext.lookup:add:194 - bsyc137_cities added to pool\n",
      "2020-08-02 22:43:41.817 | DEBUG    | flashgeotext.lookup:add:194 - bhyc138_cities added to pool\n",
      "2020-08-02 22:43:41.818 | DEBUG    | flashgeotext.lookup:add:194 - bbyc139_cities added to pool\n",
      "2020-08-02 22:43:41.818 | DEBUG    | flashgeotext.lookup:add:194 - bzyc140_cities added to pool\n",
      "2020-08-02 22:43:41.819 | DEBUG    | flashgeotext.lookup:add:194 - bjyc141_cities added to pool\n",
      "2020-08-02 22:43:41.820 | DEBUG    | flashgeotext.lookup:add:194 - bmyc142_cities added to pool\n",
      "2020-08-02 22:43:41.821 | DEBUG    | flashgeotext.lookup:add:194 - btyc143_cities added to pool\n",
      "2020-08-02 22:43:41.822 | DEBUG    | flashgeotext.lookup:add:194 - bwyc144_cities added to pool\n",
      "2020-08-02 22:43:41.823 | DEBUG    | flashgeotext.lookup:add:194 - ioyc145_cities added to pool\n",
      "2020-08-02 22:43:41.824 | DEBUG    | flashgeotext.lookup:add:194 - vgyc146_cities added to pool\n",
      "2020-08-02 22:43:41.824 | DEBUG    | flashgeotext.lookup:add:194 - bnyc147_cities added to pool\n",
      "2020-08-02 22:43:41.825 | DEBUG    | flashgeotext.lookup:add:194 - bfyc148_cities added to pool\n",
      "2020-08-02 22:43:41.826 | DEBUG    | flashgeotext.lookup:add:194 - biyc149_cities added to pool\n",
      "2020-08-02 22:43:41.827 | DEBUG    | flashgeotext.lookup:add:194 - cvyc150_cities added to pool\n",
      "2020-08-02 22:43:41.828 | DEBUG    | flashgeotext.lookup:add:194 - kyyc151_cities added to pool\n",
      "2020-08-02 22:43:41.828 | DEBUG    | flashgeotext.lookup:add:194 - clyc152_cities added to pool\n",
      "2020-08-02 22:43:41.829 | DEBUG    | flashgeotext.lookup:add:194 - cxyc153_cities added to pool\n",
      "2020-08-02 22:43:41.830 | DEBUG    | flashgeotext.lookup:add:194 - ccyc154_cities added to pool\n",
      "2020-08-02 22:43:41.831 | DEBUG    | flashgeotext.lookup:add:194 - kmyc155_cities added to pool\n",
      "2020-08-02 22:43:41.832 | DEBUG    | flashgeotext.lookup:add:194 - ckyc156_cities added to pool\n",
      "2020-08-02 22:43:41.833 | DEBUG    | flashgeotext.lookup:add:194 - cuyc157_cities added to pool\n",
      "2020-08-02 22:43:41.833 | DEBUG    | flashgeotext.lookup:add:194 - cwyc158_cities added to pool\n",
      "2020-08-02 22:43:41.834 | DEBUG    | flashgeotext.lookup:add:194 - cyyc159_cities added to pool\n",
      "2020-08-02 22:43:41.835 | DEBUG    | flashgeotext.lookup:add:194 - djyc160_cities added to pool\n",
      "2020-08-02 22:43:41.836 | DEBUG    | flashgeotext.lookup:add:194 - dmyc161_cities added to pool\n",
      "2020-08-02 22:43:41.836 | DEBUG    | flashgeotext.lookup:add:194 - tlyc162_cities added to pool\n",
      "2020-08-02 22:43:41.837 | DEBUG    | flashgeotext.lookup:add:194 - gqyc163_cities added to pool\n",
      "2020-08-02 22:43:41.838 | DEBUG    | flashgeotext.lookup:add:194 - eryc164_cities added to pool\n",
      "2020-08-02 22:43:41.839 | DEBUG    | flashgeotext.lookup:add:194 - fkyc165_cities added to pool\n",
      "2020-08-02 22:43:41.839 | DEBUG    | flashgeotext.lookup:add:194 - foyc166_cities added to pool\n",
      "2020-08-02 22:43:41.840 | DEBUG    | flashgeotext.lookup:add:194 - fjyc167_cities added to pool\n",
      "2020-08-02 22:43:41.841 | DEBUG    | flashgeotext.lookup:add:194 - pfyc168_cities added to pool\n",
      "2020-08-02 22:43:41.841 | DEBUG    | flashgeotext.lookup:add:194 - gayc169_cities added to pool\n",
      "2020-08-02 22:43:41.842 | DEBUG    | flashgeotext.lookup:add:194 - gmyc170_cities added to pool\n",
      "2020-08-02 22:43:41.843 | DEBUG    | flashgeotext.lookup:add:194 - geyc171_cities added to pool\n",
      "2020-08-02 22:43:41.844 | DEBUG    | flashgeotext.lookup:add:194 - giyc172_cities added to pool\n",
      "2020-08-02 22:43:41.845 | DEBUG    | flashgeotext.lookup:add:194 - glyc173_cities added to pool\n",
      "2020-08-02 22:43:41.845 | DEBUG    | flashgeotext.lookup:add:194 - gdyc174_cities added to pool\n",
      "2020-08-02 22:43:41.846 | DEBUG    | flashgeotext.lookup:add:194 - guyc175_cities added to pool\n",
      "2020-08-02 22:43:41.847 | DEBUG    | flashgeotext.lookup:add:194 - ggyc176_cities added to pool\n",
      "2020-08-02 22:43:41.847 | DEBUG    | flashgeotext.lookup:add:194 - gnyc177_cities added to pool\n",
      "2020-08-02 22:43:41.848 | DEBUG    | flashgeotext.lookup:add:194 - gwyc178_cities added to pool\n",
      "2020-08-02 22:43:41.849 | DEBUG    | flashgeotext.lookup:add:194 - gyyc179_cities added to pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:43:41.850 | DEBUG    | flashgeotext.lookup:add:194 - hkyc180_cities added to pool\n",
      "2020-08-02 22:43:41.850 | DEBUG    | flashgeotext.lookup:add:194 - imyc181_cities added to pool\n",
      "2020-08-02 22:43:41.851 | DEBUG    | flashgeotext.lookup:add:194 - jeyc182_cities added to pool\n",
      "2020-08-02 22:43:41.852 | DEBUG    | flashgeotext.lookup:add:194 - kiyc183_cities added to pool\n",
      "2020-08-02 22:43:41.852 | DEBUG    | flashgeotext.lookup:add:194 - xkyc184_cities added to pool\n",
      "2020-08-02 22:43:41.853 | DEBUG    | flashgeotext.lookup:add:194 - kwyc185_cities added to pool\n",
      "2020-08-02 22:43:41.854 | DEBUG    | flashgeotext.lookup:add:194 - kgyc186_cities added to pool\n",
      "2020-08-02 22:43:41.854 | DEBUG    | flashgeotext.lookup:add:194 - lsyc187_cities added to pool\n",
      "2020-08-02 22:43:41.855 | DEBUG    | flashgeotext.lookup:add:194 - lryc188_cities added to pool\n",
      "2020-08-02 22:43:41.856 | DEBUG    | flashgeotext.lookup:add:194 - liyc189_cities added to pool\n",
      "2020-08-02 22:43:41.856 | DEBUG    | flashgeotext.lookup:add:194 - luyc190_cities added to pool\n",
      "2020-08-02 22:43:41.857 | DEBUG    | flashgeotext.lookup:add:194 - moyc191_cities added to pool\n",
      "2020-08-02 22:43:41.858 | DEBUG    | flashgeotext.lookup:add:194 - mkyc192_cities added to pool\n",
      "2020-08-02 22:43:41.858 | DEBUG    | flashgeotext.lookup:add:194 - mwyc193_cities added to pool\n",
      "2020-08-02 22:43:41.859 | DEBUG    | flashgeotext.lookup:add:194 - mvyc194_cities added to pool\n",
      "2020-08-02 22:43:41.860 | DEBUG    | flashgeotext.lookup:add:194 - mtyc195_cities added to pool\n",
      "2020-08-02 22:43:41.861 | DEBUG    | flashgeotext.lookup:add:194 - mhyc196_cities added to pool\n",
      "2020-08-02 22:43:41.861 | DEBUG    | flashgeotext.lookup:add:194 - muyc197_cities added to pool\n",
      "2020-08-02 22:43:41.862 | DEBUG    | flashgeotext.lookup:add:194 - ytyc198_cities added to pool\n",
      "2020-08-02 22:43:41.863 | DEBUG    | flashgeotext.lookup:add:194 - fmyc199_cities added to pool\n",
      "2020-08-02 22:43:41.863 | DEBUG    | flashgeotext.lookup:add:194 - mdyc200_cities added to pool\n",
      "2020-08-02 22:43:41.864 | DEBUG    | flashgeotext.lookup:add:194 - mcyc201_cities added to pool\n",
      "2020-08-02 22:43:41.865 | DEBUG    | flashgeotext.lookup:add:194 - mnyc202_cities added to pool\n",
      "2020-08-02 22:43:41.866 | DEBUG    | flashgeotext.lookup:add:194 - meyc203_cities added to pool\n",
      "2020-08-02 22:43:41.866 | DEBUG    | flashgeotext.lookup:add:194 - msyc204_cities added to pool\n",
      "2020-08-02 22:43:41.867 | DEBUG    | flashgeotext.lookup:add:194 - mzyc205_cities added to pool\n",
      "2020-08-02 22:43:41.868 | DEBUG    | flashgeotext.lookup:add:194 - mmyc206_cities added to pool\n",
      "2020-08-02 22:43:41.868 | DEBUG    | flashgeotext.lookup:add:194 - nryc207_cities added to pool\n",
      "2020-08-02 22:43:41.869 | DEBUG    | flashgeotext.lookup:add:194 - nlyc208_cities added to pool\n",
      "2020-08-02 22:43:41.870 | DEBUG    | flashgeotext.lookup:add:194 - ncyc209_cities added to pool\n",
      "2020-08-02 22:43:41.871 | DEBUG    | flashgeotext.lookup:add:194 - nuyc210_cities added to pool\n",
      "2020-08-02 22:43:41.871 | DEBUG    | flashgeotext.lookup:add:194 - mpyc211_cities added to pool\n",
      "2020-08-02 22:43:41.872 | DEBUG    | flashgeotext.lookup:add:194 - pwyc212_cities added to pool\n",
      "2020-08-02 22:43:41.872 | DEBUG    | flashgeotext.lookup:add:194 - pgyc213_cities added to pool\n",
      "2020-08-02 22:43:41.873 | DEBUG    | flashgeotext.lookup:add:194 - pnyc214_cities added to pool\n",
      "2020-08-02 22:43:41.874 | DEBUG    | flashgeotext.lookup:add:194 - pryc215_cities added to pool\n",
      "2020-08-02 22:43:41.875 | DEBUG    | flashgeotext.lookup:add:194 - qayc216_cities added to pool\n",
      "2020-08-02 22:43:41.875 | DEBUG    | flashgeotext.lookup:add:194 - reyc217_cities added to pool\n",
      "2020-08-02 22:43:41.876 | DEBUG    | flashgeotext.lookup:add:194 - rwyc218_cities added to pool\n",
      "2020-08-02 22:43:41.877 | DEBUG    | flashgeotext.lookup:add:194 - blyc219_cities added to pool\n",
      "2020-08-02 22:43:41.878 | DEBUG    | flashgeotext.lookup:add:194 - shyc220_cities added to pool\n",
      "2020-08-02 22:43:41.878 | DEBUG    | flashgeotext.lookup:add:194 - knyc221_cities added to pool\n",
      "2020-08-02 22:43:41.879 | DEBUG    | flashgeotext.lookup:add:194 - lcyc222_cities added to pool\n",
      "2020-08-02 22:43:41.879 | DEBUG    | flashgeotext.lookup:add:194 - mfyc223_cities added to pool\n",
      "2020-08-02 22:43:41.880 | DEBUG    | flashgeotext.lookup:add:194 - pmyc224_cities added to pool\n",
      "2020-08-02 22:43:41.881 | DEBUG    | flashgeotext.lookup:add:194 - vcyc225_cities added to pool\n",
      "2020-08-02 22:43:41.881 | DEBUG    | flashgeotext.lookup:add:194 - smyc226_cities added to pool\n",
      "2020-08-02 22:43:41.882 | DEBUG    | flashgeotext.lookup:add:194 - styc227_cities added to pool\n",
      "2020-08-02 22:43:41.882 | DEBUG    | flashgeotext.lookup:add:194 - scyc228_cities added to pool\n",
      "2020-08-02 22:43:41.883 | DEBUG    | flashgeotext.lookup:add:194 - slyc229_cities added to pool\n",
      "2020-08-02 22:43:41.884 | DEBUG    | flashgeotext.lookup:add:194 - sxyc230_cities added to pool\n",
      "2020-08-02 22:43:41.885 | DEBUG    | flashgeotext.lookup:add:194 - siyc231_cities added to pool\n",
      "2020-08-02 22:43:41.885 | DEBUG    | flashgeotext.lookup:add:194 - sbyc232_cities added to pool\n",
      "2020-08-02 22:43:41.886 | DEBUG    | flashgeotext.lookup:add:194 - ssyc233_cities added to pool\n",
      "2020-08-02 22:43:41.886 | DEBUG    | flashgeotext.lookup:add:194 - lkyc234_cities added to pool\n",
      "2020-08-02 22:43:41.887 | DEBUG    | flashgeotext.lookup:add:194 - sryc235_cities added to pool\n",
      "2020-08-02 22:43:41.887 | DEBUG    | flashgeotext.lookup:add:194 - szyc236_cities added to pool\n",
      "2020-08-02 22:43:41.888 | DEBUG    | flashgeotext.lookup:add:194 - twyc237_cities added to pool\n",
      "2020-08-02 22:43:41.888 | DEBUG    | flashgeotext.lookup:add:194 - tjyc238_cities added to pool\n",
      "2020-08-02 22:43:41.889 | DEBUG    | flashgeotext.lookup:add:194 - tzyc239_cities added to pool\n",
      "2020-08-02 22:43:41.890 | DEBUG    | flashgeotext.lookup:add:194 - tgyc240_cities added to pool\n",
      "2020-08-02 22:43:41.890 | DEBUG    | flashgeotext.lookup:add:194 - tkyc241_cities added to pool\n",
      "2020-08-02 22:43:41.891 | DEBUG    | flashgeotext.lookup:add:194 - toyc242_cities added to pool\n",
      "2020-08-02 22:43:41.892 | DEBUG    | flashgeotext.lookup:add:194 - ttyc243_cities added to pool\n",
      "2020-08-02 22:43:41.892 | DEBUG    | flashgeotext.lookup:add:194 - tcyc244_cities added to pool\n",
      "2020-08-02 22:43:41.893 | DEBUG    | flashgeotext.lookup:add:194 - tvyc245_cities added to pool\n",
      "2020-08-02 22:43:41.894 | DEBUG    | flashgeotext.lookup:add:194 - ugyc246_cities added to pool\n",
      "2020-08-02 22:43:41.895 | DEBUG    | flashgeotext.lookup:add:194 - uzyc247_cities added to pool\n",
      "2020-08-02 22:43:41.896 | DEBUG    | flashgeotext.lookup:add:194 - vuyc248_cities added to pool\n",
      "2020-08-02 22:43:41.898 | DEBUG    | flashgeotext.lookup:add:194 - veyc249_cities added to pool\n",
      "2020-08-02 22:43:41.900 | DEBUG    | flashgeotext.lookup:add:194 - wfyc250_cities added to pool\n",
      "2020-08-02 22:43:41.902 | DEBUG    | flashgeotext.lookup:add:194 - ehyc251_cities added to pool\n",
      "2020-08-02 22:43:41.904 | DEBUG    | flashgeotext.lookup:add:194 - yeyc252_cities added to pool\n",
      "2020-08-02 22:43:41.905 | DEBUG    | flashgeotext.lookup:add:194 - vcyc253_cities added to pool\n",
      "2020-08-02 22:43:41.907 | DEBUG    | flashgeotext.lookup:add:194 - uzyc254_cities added to pool\n",
      "2020-08-02 22:43:41.908 | DEBUG    | flashgeotext.lookup:add:194 - ttyc255_cities added to pool\n",
      "2020-08-02 22:43:41.913 | DEBUG    | flashgeotext.lookup:add:194 - lsyc256_cities added to pool\n",
      "2020-08-02 22:43:41.917 | DEBUG    | flashgeotext.lookup:add:194 - siyc257_cities added to pool\n",
      "2020-08-02 22:43:41.921 | DEBUG    | flashgeotext.lookup:add:194 - reyc258_cities added to pool\n",
      "2020-08-02 22:43:41.925 | DEBUG    | flashgeotext.lookup:add:194 - pgyc259_cities added to pool\n",
      "2020-08-02 22:43:41.927 | DEBUG    | flashgeotext.lookup:add:194 - vuyc260_cities added to pool\n",
      "2020-08-02 22:43:41.930 | DEBUG    | flashgeotext.lookup:add:194 - knyc261_cities added to pool\n",
      "2020-08-02 22:43:41.932 | DEBUG    | flashgeotext.lookup:add:194 - mcyc262_cities added to pool\n",
      "2020-08-02 22:43:41.933 | DEBUG    | flashgeotext.lookup:add:194 - kgyc263_cities added to pool\n",
      "2020-08-02 22:43:41.934 | DEBUG    | flashgeotext.lookup:add:194 - xkyc264_cities added to pool\n",
      "2020-08-02 22:43:41.935 | DEBUG    | flashgeotext.lookup:add:194 - hkyc265_cities added to pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-02 22:43:41.936 | DEBUG    | flashgeotext.lookup:add:194 - wfyc266_cities added to pool\n",
      "2020-08-02 22:43:41.938 | DEBUG    | flashgeotext.lookup:add:194 - gqyc267_cities added to pool\n",
      "2020-08-02 22:43:41.940 | DEBUG    | flashgeotext.lookup:add:194 - kmyc268_cities added to pool\n",
      "2020-08-02 22:43:41.940 | DEBUG    | flashgeotext.lookup:add:194 - mmyc269_cities added to pool\n",
      "2020-08-02 22:43:41.942 | DEBUG    | flashgeotext.lookup:add:194 - bmyc270_cities added to pool\n",
      "2020-08-02 22:43:41.943 | DEBUG    | flashgeotext.lookup:add:194 - bjyc271_cities added to pool\n",
      "2020-08-02 22:43:41.944 | DEBUG    | flashgeotext.lookup:add:194 - agyc272_cities added to pool\n",
      "2020-08-02 22:43:41.945 | DEBUG    | flashgeotext.lookup:add:194 - ehyc273_cities added to pool\n",
      "2020-08-02 22:43:41.946 | DEBUG    | flashgeotext.lookup:add:194 - pmyc274_cities added to pool\n",
      "2020-08-02 22:43:42.027 | DEBUG    | flashgeotext.lookup:add:194 - indian_cities added to pool\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "districts = {\n",
    "    'Thrissur': createUpperAndLowerCase('Thrissur'),\n",
    "    'Guntur': createUpperAndLowerCase('Guntur'),\n",
    "    'Rajahmundry': createUpperAndLowerCase('Rajahmundry'),\n",
    "    'Durg': createUpperAndLowerCase('Durg'),\n",
    "}\n",
    "\n",
    "lookup_districts = LookupData(\n",
    "    name=\"indian_cities\",\n",
    "    data=unique_cities_india\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "geotext = GeoText(use_demo_data=True)\n",
    "addCity1([\"Stjohns\"],'AG17',special=0)\n",
    "addCity1([\"St. George's\"],'GD17',special=0)\n",
    "addCity1([\"Portofspain\"],'TT17',special=0)\n",
    "addCity1([\"Malé\"],'MV17',special=0)\n",
    "addCity1([\"Nuku'alofa\",'Nukualofa'],'TO17',special=0)\n",
    "addCity1([\"BSE\",'Bse','B.S.E.','B.s.e.','Rbi','RBI','Cbi','Cid','CBI','CID'],'IN17',special=1)\n",
    "addCity1(['Kempegowda Nagar','Kempegowdanagar','Perambur','Vallanadu','Thoothukudi','Bombay Stock Exchange','Kashmir','Erragadda','Nagapattinam','Nagappattinam','Taj Mahal','Tiruchi','Bollywood','Keerapakkam', 'Tambaram','Kannada','Indrakeeladri','Dhinkia','Havelock Island'],'IN18',special=0)\n",
    "addCity1([\"dharna\",'Dharna'],'IN19',special=0)\n",
    "\n",
    "addCity1(['Hobart','Sydney','Perth','Melbourne','NSW','New South Wales','Queensland','Tuggeranong','Bondi Beach','Flemington','Warracknabeal','Tasmania','Belconnen','Lesmurdie','Donvale','Weetangera','Lancefield', 'Cobaw', 'Benloch', 'Pastoria', 'Baynton','Saint George','St George','Kogarah','Victoria'], 'AUX', special=0)\n",
    "addCity1(['Dhaka'], 'BDX', special=0)\n",
    "addCity1(['Athens','Moria'], 'GRX', special=0)\n",
    "addCity1(['Jalalabad','Kandahar','Herat'], 'AFX', special=0)\n",
    "addCity1(['Paris','Lyon','Dordogne','Stade de France'], 'FRX', special=0)\n",
    "addCity1(['Niger Delta','Borno','Nigeria','Lagos','Ogun'],'NGX', special=0)\n",
    "addCity1(['EU','European Union','E.U.','Eu','European Commission','European Investment Bank','Euro','euro'], 'EUX', special=1)\n",
    "addCity1(['UN','United Nations','U.N.','Un'], 'UNX', special=1)\n",
    "addCity1(['Bali'],'IDX', special=0)\n",
    "addCity1(['Damascus'],'SYX', special=0)\n",
    "addCity1(['Santa Maria','Rio Olympic','Rio Olympics','Rio 2016'],'BRX', special=0)\n",
    "addCity1(['Moscow','Saint Petersburg','St. Petersburg'],'RUX', special=0)\n",
    "addCity1(['Newengland','Albany','Tippecanoe','St. Augustine','Vilano Beach','St. Tammany','District of Columbia','Bryant Park','Charlotte','Boro Park','Roseburg','Marrero','Montauk','Long Island','Capitol Hill','Syracuse','Georgetown','New Smyrna Beach','Palm Beach','North Little Rock','St. Louis','Port Saint Lucie','Central Park','America','Queens','Lawrence','Williamsburg','Washington','Washington, D.C.','Prairie View','Santa Clara', 'San Jose', 'Santa Cruz', 'Hudson Valley','Kitsap County','Harvard','Mount Sinai','Putnam County','Goddard Park',\"Hawai'i\",'Davis','Calaveras County','Wall Street','Carroll County','Humboldt County','Neshannock','Penn','Yale','Federal Reserve','NYC','N.Y.C.','San Francisco', 'San Mateo','Worcester','Johnson City','Cdc','Harlem','NYPD','St Louis','Fox Lake','Pentagon','Richmond','Telluride','White House'],'USX1',special=0)\n",
    "addCity1(['Usa','Dow','Buffalo','BUFFALO','Democrat','Democrats','Republican','Republicans','Senator','FBI','Fbi','F.B.I.','Us','Nasa','NASA','Sen.','Fed','GOP','Gop','Centers for Disease Control and Prevention'],'USX2', special=1)\n",
    "addCity1(us_state_names,'US11', special=1)\n",
    "addCity1(['Haiti','Portauprince'],'HTX', special=0)\n",
    "addCity1(['Mali'],'MLX', special=0)\n",
    "addCity1(['Cabo Delgado', 'Ancuabe', 'Mozambique'],'MZX', special=0)\n",
    "addCity1(['Pama'],'BFX', special=0)\n",
    "addCity1(['Papuanewguinea'],'PGX',special=0)\n",
    "addCity1(['Grimsby','Lincolnshire','Widnes','Middlesex','Cambridge','Oxford','London','Ascension Island','Newcastle','British','Somerset','Bristol','Carterton','Derbyshire','West Hampstead','Romsey','Tottenham','Sky Sports','West Hampstead','Kent','Brighton','Cornwall','Westminster','Boosbeck','Yorkshire','Chelsea','Manchester','Norwich','Norfolk','Birmingham', 'England', 'Wales', 'Northern Ireland', 'Scotland','Manchester','Richmond and Twickenham','Britain','Clogher','Wandsworth','Cronton','Inverurie','Peak District', 'Snowdonia', 'Dorset','Dundee','Salisbury','Suffolk'],'GBX3',special=0)\n",
    "addCity1(['Uk','Gbr','GBR','Boris Johnson','NHS','Nhs','nhs','£'],'GBX4',special=1)\n",
    "addCity1(['Vigui'],'PAX',special=0)\n",
    "addCity1(['Somalia'],'SO11',special=0)\n",
    "addCity1(['Wellington','Albert Town','Queenstown','Napier','Waitarere','Levin'],'NZ11',special=0)\n",
    "addCity1(['Frankfurt','Nürnberg','Nuremberg','Cologne','Jena','Melle','Achim','Auerbach'],'DE11',special=0)\n",
    "addCity1(['Venice','Milan','San Siro','San Donato Milanese'],'IT11',special=0)\n",
    "addCity1(['Vienna','Nickelsdorf','Sölden','Soelden'],'AT11',special=0)\n",
    "addCity1(['Syria','Idlib'],'SY11',special=0)\n",
    "addCity1(['Yemen','Mokha','Mocha',\"Sa'dah\",'Saada'],'YE11',special=0)\n",
    "addCity1(['Vernon','Trans Mountain','TransMountain','Newfoundland','Labrador','Harrison Hot Springs','Victoria'],'CA11',special=0)\n",
    "addCity1(['Tiananmen Square','Guangdong','Peking','Urumqi',\"Xi’an\",\"Xi'an\",'Xian','Jiangsu','Hunan','Kashgar'],'CN11',special=0)\n",
    "addCity1(['Duma','Hamas','Eastjerusalem'],'PS11',special=0)\n",
    "addCity1(['Roszke'],'HU11',special=0)\n",
    "addCity1(['El Salvador'],'SV11',special=0)\n",
    "addCity1(['DRC','Kasai','Drc'],'CD11',special=1)\n",
    "addCity1(['Rcongo'],'CG11',special=1)\n",
    "addCity1(['Naguru','Kampala','Uganda','Entebbe'],'UG11',special=0)\n",
    "addCity1(['Cotopaxi','Ecuador'],'EC11',special=0)\n",
    "addCity1(['Jerusalem','Hadera','Yerushalayim','Bnei Brak','Safed'],'IL11',special=0)\n",
    "addCity1(['Cyprus'],'CY11',special=0)\n",
    "addCity1(['Santo Domingo','Dominican Republic'],'DO11',special=0)\n",
    "addCity1(['Chiang Mai'],'TH11',special=0)\n",
    "addCity1(['Holland','Nederland'],'NL12',special=0)\n",
    "addCity1(['Bermuda'],'BM11',special=0)\n",
    "addCity1(['Kim Jong Un','DPRK','Dprk','D.P.R.K.'],'KP11',special=1)\n",
    "addCity1(['Tenerife','Canary Islands','Barcelona','Catalonia'],'ES11',special=0)\n",
    "addCity1(['Tshwane','Limpopo','Maritzburg','Mankweng','Manenberg','Ficksburg','Bellville','Ekurhuleni','Suikerbosrand','Eastern Cape','Western Cape','De Doorns','Daveyton','Gauteng','De Deur','Nongoma','Khayelitsha','Modderpoort','Free State','Mafikeng','Mosselbay','Mossel Bay','Pollsmoor','Tlokwe','Brandfort','Boikhutso', 'Welgevonden', 'Goedgevonden','Kakamas','Sterkspruit', 'Engcobo','Ngcobo', 'Gugwini', 'Silindile', 'Moyeni'],'ZA11',special=0)\n",
    "addCity1(['Mahé','Seychelles'],'SC11',special=0)\n",
    "addCity1(['Gorgan','Golestan','Tehran','Bandar Abbas'],'IR11',special=0)\n",
    "addCity1(['Qatar'],'QA11',special=0)\n",
    "addCity1(['Zurich','Geneva'],'CH11',special=0)\n",
    "addCity1(['Sint Maarten','St. Maarten','St Maarten'],'SX11',special=0)\n",
    "addCity1(['UAE','Uae','U.A.E.'],'AE11',special=1)\n",
    "addCity1(['Bahamas'],'BS11',special=0)\n",
    "addCity1(['Hanoi','Ha Noi', 'Vu Duc Dam','Ho Chi Mihn City','Hà Nội'],'VN11',special=0)\n",
    "addCity1(['Gothenburg','Sweden'],'SE11',special=0)\n",
    "addCity1(['Muranga'],'KE11',special=0)\n",
    "addCity1(['Belize','Bdf'],'BZ11',special=0)\n",
    "addCity1(['Antarctica'],'AQ11',special=0)\n",
    "addCity1(['Niger'],'NE11',special=0)\n",
    "addCity1(['Murilo'],'FM11',special=0)\n",
    "addCity1(['Fukushima','Omura','Fukuoka'],'JP11',special=0)\n",
    "addCity1(['Porto'],'PT11',special=0)\n",
    "addCity1(['Apia','Samoa'],'WS',special=0)\n",
    "addCity1(['Libya'],'LY11',special=0)\n",
    "addCity1(['Istanbul'],'TR11',special=0)\n",
    "addCity1(['Fiji'],'FJ11',special=0)\n",
    "addCity1(['Nuuk','Greenland'],'GL11',special=0)\n",
    "addCity1(['Tajikistan'],'TJ11',special=0)\n",
    "addCity1(['Uzbekistan'],'UZ11',special=0)\n",
    "addCity1(['Auki', 'Solomon Islands'],'SB11',special=0)\n",
    "addCity1(['Chernobyl'],'UA11',special=0)\n",
    "addCity1(['Hong KONG'],'HK12',special=1)\n",
    "addCity1(['Malta'],'MT11',special=0)\n",
    "addCity1(['Namibia'],'NAX11',special=0)\n",
    "addCity1(['Bosnia-Herzegovina'],'BA11',special=0)\n",
    "addCity1(['Dominica'],'DM11',special=0)\n",
    "addCity1(['Togo'],'TG11',special=0)\n",
    "addCity1(['St. Peter’s Square', 'Saint Peter’s Square','St. Peter’s Basilica','Saint Peter’s Basilica'],'VA11',special=0)\n",
    "addCity1(['Ashanti Region','Ho Municipal','Ho Municipality'],'GH11',special=0)\n",
    "addCity1(['Praia'],'CV11',special=0)\n",
    "addCity1(['Mullaitivu'],'LK14',special=0)\n",
    "addCity1(['Mexicocity'],'MX14',special=1)\n",
    "addCity1(['Sierra Leone'],'SL14',special=0)\n",
    "addCity1(['Porto-Novo','Porto Novo','Portonovo'],'BJ14',special=0)\n",
    "\n",
    "addCity1(['San José'],'CR14',special=0)\n",
    "addCity1([\"Stgeorges\"],'GD14',special=0)\n",
    "addCity1([\"Chisinau\"],'MD14',special=0)\n",
    "addCity1([\"Victoria\"],'SC14',special=0)\n",
    "addCity1([\"Juba\"],'SS14',special=0)\n",
    "addCity1([\"Sri Jayawardenapura Kotte\"],'LK15',special=0)\n",
    "addCity1(['George Town'],'MY15',special=0)\n",
    "\n",
    "\n",
    "addCity1(['Angola'],'AO21',special=0)\n",
    "addCity1(['Antigua and Barbuda','Antigua & Barbuda','Antigua','Barbuda'],'AG21',special=0)\n",
    "addCity1(['Bosnia and Herzegovina','Bosnia & Herzegovina','Bosnia','Herzegovina'],'BA21',special=0)\n",
    "addCity1(['EquatorialGuinea'],'GQ21',special=0)\n",
    "addCity1(['Eritrea'],'ER21',special=0)\n",
    "addCity1(['Gambia'],'GM21',special=0)\n",
    "addCity1(['Granada'],'NI21',special=0)\n",
    "addCity1(['Guinea'],'GN21',special=0)\n",
    "addCity1(['Honduras'],'HN21',special=0)\n",
    "addCity1(['Liechtenstein'],'LI21',special=0)\n",
    "addCity1(['Macedonia'],'MK21',special=0)\n",
    "addCity1(['Marshallislands'],'MH21',special=0)\n",
    "addCity1(['Mauritius'],'MU21',special=0)\n",
    "addCity1(['Micronesia'],'FM21',special=0)\n",
    "addCity1(['Mongolia'],'MN21',special=0)\n",
    "addCity1(['Nicaragua'],'NI21',special=0)\n",
    "addCity1(['Palestine'],'PS21',special=0)\n",
    "addCity1(['Paraguay'],'PY21',special=0)\n",
    "addCity1(['Senegal'],'SN21',special=0)\n",
    "addCity1(['Swaziland'],'SZ21',special=0)\n",
    "addCity1(['Turkmenistan'],'TM21',special=0)\n",
    "addCity1(['Uruguay'],'UY21',special=0)\n",
    "addCity1(['Saintkittsandnevis'],'KN21',special=0)\n",
    "addCity1(['Saintlucia'],'LC21',special=0)\n",
    "addCity1(['Saintvincentandthegrenadines'],'VC21',special=0)\n",
    "addCity1(['Southsudan'],'SS21',special=0)\n",
    "addCity1(['Trinidadandtobago'],'TT21',special=0)\n",
    "addCity1(['Unitedarabemirates'],'AE21',special=0)\n",
    "addCity1(['Guineabissau','Bissau'],'GW21',special=0)\n",
    "addCity1(['Georgia'],'GE21',special=0)\n",
    "addCity1(['Britishcolumbia'],'CA21',special=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "addCity1(can_provinces, 'CA17',special=0)\n",
    "\n",
    "addCity1(['Balochistan', 'Khyber Pakhtunkhwa', 'Sindh'],'PK11',special=0)\n",
    "\n",
    "\n",
    "addCity1(can_abbreviations2, 'CA18',special=1)\n",
    "addCity1(['Killarney','Dublin'], 'IE11',special=0)\n",
    "addCity1(['Saint Joseph','St. Joseph'], 'TT11', special=0)\n",
    "addCity1(['Hong Kong','HK','H.K.','Causeway Bay','Mong Kok','Lung Wo Road'], 'HK11',special=0)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(missing_countries)):\n",
    "    addCity1([str(missing_countries_names[missing_countries[i]]), \n",
    "             str(missing_countries_capitals[missing_countries[i]])], missing_countries[i].lower()+'XC13', special=0)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(plural_nationalities)):\n",
    "    try:\n",
    "        #print(i, plural_nationalities['country_code'][i])\n",
    "        addCity1(getPlural(plural_nationalities['plural_country'][i]), plural_nationalities['country_code'][i]+'YC'+str(i), special=0)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "lookup_districts_india = LookupData(\n",
    "    name=\"indian_cities\",\n",
    "    data=combined_cities_india\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "geotext.add(lookup_districts_india)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(dict(geotext.extract(input_text='Alex Castro', span_info=True))['cities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kenyan', 'Kenyans', \"Kenyan's\"]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPlural(plural_nationalities['plural_country'][58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geotext.extract(input_text='British', span_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n"
     ]
    }
   ],
   "source": [
    "#print(len(geotext.pool))\n",
    "\n",
    "\n",
    "#print(geotext.pool)\n",
    "\n",
    "#geotext.extract(input_text, span_info=True)\n",
    "\n",
    "list_preds = []\n",
    "#end_of_range = len(df)\n",
    "#end_of_range = 2000\n",
    "\n",
    "for i in range(0, end_of_range):\n",
    "    list_preds.append(geotext.extract(input_text=df['cleaned_text'][i], span_info=True))\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['cleaned_text'][149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_preds[149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for i in range(0,len(df)):\n",
    "    #print(i, list_preds[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#geotext.extract(input_text=df['cleaned_text'][2738], span_info=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_preds[0]['cities'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0 ,end_of_range):\n",
    "    print(i)\n",
    "    #temp_test = list(geotext.extract(input_text=df['cleaned_text'][i], span_info=True)['cities'].keys())\n",
    "    #temp_test2 = list(geotext.extract(input_text=df['cleaned_text'][i], span_info=True)['countries'].keys())\n",
    "    for j in range(0,len(delete_these_words)):\n",
    "        #print(i, delete_these_words[j])\n",
    "        \n",
    "        list_preds[i]['cities'].pop(delete_these_words[j], None)\n",
    "        list_preds[i]['countries'].pop(delete_these_words[j], None)\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            while True:\n",
    "                try:\n",
    "                    del list_preds[i]['cities'][delete_these_words[j]]\n",
    "                except:\n",
    "                    pass\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                try:\n",
    "                    del list_preds[i]['countries'][delete_these_words[j]]\n",
    "                except:\n",
    "                    pass\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "        #del list_preds[i]['cities'][delete_these_words[j]]\n",
    "        #list_preds[i]['cities'] = dict(list(filter(lambda a: a != delete_these_words[j], temp_test)))\n",
    "        \n",
    "    #list_preds[i]['cities'] = temp_test\n",
    "    #list_preds[i]['countries'] = temp_test2\n",
    "        \n",
    "        #del list_preds[i]['countries'][delete_these_words[j]]\n",
    "        #list_preds[i]['countries'] = dict(list(filter(lambda a: a != delete_these_words[j], temp_test2)))\n",
    "\n",
    "        #print(list_preds[i]['cities'])\n",
    "        #print(i, \"deleted\", delete_these_words[j])\n",
    "        \n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_preds[149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'] \n",
    "for i in range(0,len(months)):\n",
    "    months.append(months[i].lower())\n",
    "for i in range(0,len(months)):\n",
    "    months.append(months[i].upper())\n",
    "for i in range(0,len(months)):\n",
    "    months.append(months[i][0:3])\n",
    "for i in range(0,len(months)):\n",
    "    months.append(months[i][0:3].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "countries_from_cities = {}\n",
    "\n",
    "for i in range(0, end_of_range):\n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "    cities_sorted_by_count = sorted(list_preds[i]['cities'].items(),key=lambda x:getitem(x[1],'count'), reverse=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    remove_less_than_3 = []\n",
    "    keys_of_cities = list(dict(cities_sorted_by_count).keys())\n",
    "    for i in range(0, len(keys_of_cities)):\n",
    "        if len(keys_of_cities[i])<=3:\n",
    "            remove_less_than_3.append(i)\n",
    "\n",
    "    for i in range(0,len(remove_less_than_3)):\n",
    "        del cities_sorted_by_count[remove_less_than_3[i]]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    #print(i, cities_sorted_by_count)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(0,len(cities_sorted_by_count)):\n",
    "        temp_city_name = str(cities_sorted_by_count[j][0])\n",
    "        temp_city_name = unidecode.unidecode(temp_city_name)\n",
    "        cities_sorted_by_count[j] = list(cities_sorted_by_count[j])\n",
    "        cities_sorted_by_count[j][0] = ''.join(temp_city_name)\n",
    "        cities_sorted_by_count[j] = tuple(cities_sorted_by_count[j])\n",
    "    \n",
    "    indian_cities_sorted_by_count = sorted(list_preds[i]['indian_cities'].items(),key=lambda x:getitem(x[1],'count'), reverse=True)\n",
    "\n",
    "    city_names_normal = []\n",
    "    city_names_normal_counts = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    countries_sorted_by_count = sorted(list_preds[i]['countries'].items(),key=lambda x:getitem(x[1],'count'), reverse=True)\n",
    "\n",
    "\n",
    "    countries_names = []\n",
    "    for m in range(0, len(countries_sorted_by_count)):\n",
    "        countries_names.append(countries_sorted_by_count[m][0])\n",
    "\n",
    "    dict_country_counts_normal = {}\n",
    "    for m in range(0, len(countries_names)):\n",
    "        dict_country_counts_normal[m] = 0\n",
    "\n",
    "    for m in range(0, len(countries_sorted_by_count)):\n",
    "        for p in range(0, countries_sorted_by_count[m][1]['count']):\n",
    "            \n",
    "            temp_loc_of_chars = countries_sorted_by_count[m][1]['span_info'][p][0]\n",
    "            temp_loc_of_chars_end = countries_sorted_by_count[m][1]['span_info'][p][1]\n",
    "            \n",
    "            earlier_3_chars = df['cleaned_text'][i][temp_loc_of_chars-3:temp_loc_of_chars]\n",
    "            later_2_chars = df['cleaned_text'][i][temp_loc_of_chars_end:temp_loc_of_chars_end+2]\n",
    "            \n",
    "            if temp_loc_of_chars<20:\n",
    "                    later_and_before_20_chars = df['cleaned_text'][i][0:temp_loc_of_chars_end+20]\n",
    "            if temp_loc_of_chars>=20:\n",
    "                    later_and_before_20_chars = df['cleaned_text'][i][temp_loc_of_chars-20:temp_loc_of_chars_end+20]\n",
    "            \n",
    "            check_if_month_present = [ele for ele in months if(ele in later_and_before_20_chars)]\n",
    "            \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            conditions_to_check = (check_if_month_present!=[] and temp_loc_of_chars<=250)\n",
    "            \n",
    "            print('conditions satisfied?', conditions_to_check)\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            \n",
    "            if (temp_loc_of_chars<=20):\n",
    "                dict_country_counts_normal[m] += 17\n",
    "            if (temp_loc_of_chars>20 and temp_loc_of_chars<=100):\n",
    "                dict_country_counts_normal[m] += 10\n",
    "            if (temp_loc_of_chars>100 and temp_loc_of_chars<=250):\n",
    "                dict_country_counts_normal[m] += 7\n",
    "            if (temp_loc_of_chars>=250 and temp_loc_of_chars<=1000):\n",
    "                dict_country_counts_normal[m] += 5\n",
    "            if (temp_loc_of_chars>1000):\n",
    "                dict_country_counts_normal[m] += 2\n",
    "                \n",
    "            if ('in' in earlier_3_chars): \n",
    "                if (temp_loc_of_chars<=50):\n",
    "                    dict_country_counts_normal[m] += 25\n",
    "                elif temp_loc_of_chars>50 and temp_loc_of_chars<=100:\n",
    "                    dict_country_counts_normal[m] += 20\n",
    "                elif temp_loc_of_chars>100 and temp_loc_of_chars<=250:\n",
    "                    dict_country_counts_normal[m] += 15\n",
    "                \n",
    "            \"\"\"\n",
    "            if (conditions_to_check==True):\n",
    "                print('ps3190', m)\n",
    "                dict_country_counts_normal[m] += 20\n",
    "            \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    countries_counts = list(dict_country_counts_normal.values())\n",
    "    #print(countries_names, countries_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for j in range(0,len(cities_sorted_by_count)):\n",
    "        city_names_normal.append(cities_sorted_by_count[j][0])\n",
    "        #city_names_normal_counts.append(cities_sorted_by_count[j][1]['count'])\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #city_names_normal = city_names_normal_from_listpreds\n",
    "    \n",
    "    \n",
    "    \n",
    "    city_names_normal_from_listpreds = list(list_preds[i]['cities'].keys())\n",
    "    dict_counts_normal = {}\n",
    "    for m in range(0, len(city_names_normal_from_listpreds)):\n",
    "        dict_counts_normal[m] = 0\n",
    "\n",
    "    for m in range(0, len(city_names_normal_from_listpreds)):\n",
    "        for p in range(0, len(list_preds[i]['cities'][city_names_normal_from_listpreds[m]]['span_info'])):\n",
    "            temp_loc_of_chars = list_preds[i]['cities'][city_names_normal_from_listpreds[m]]['span_info'][p][0]\n",
    "            \n",
    "            temp_loc_of_chars_end = list_preds[i]['cities'][city_names_normal_from_listpreds[m]]['span_info'][p][1]\n",
    "            \n",
    "            earlier_3_chars = df['cleaned_text'][i][temp_loc_of_chars-3:temp_loc_of_chars]\n",
    "            later_2_chars = df['cleaned_text'][i][temp_loc_of_chars_end:temp_loc_of_chars_end+2]\n",
    "            \n",
    "            \n",
    "            if temp_loc_of_chars<20:\n",
    "                    later_and_before_20_chars = df['cleaned_text'][i][0:temp_loc_of_chars_end+20]\n",
    "            if temp_loc_of_chars>=20:\n",
    "                    later_and_before_20_chars = df['cleaned_text'][i][temp_loc_of_chars-20:temp_loc_of_chars_end+20]\n",
    "            \n",
    "            \n",
    "            check_if_month_present = [ele for ele in months if(ele in later_and_before_20_chars)] \n",
    "            \n",
    "            \n",
    "            conditions_to_check = (check_if_month_present!=[] and temp_loc_of_chars<=250)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #print('conditions satisfied?', conditions_to_check)\n",
    "            \n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            if ((',' in earlier_4_chars) or (',' in later_4_chars) or (':' in earlier_4_chars)\n",
    "                or (':' in later_4_chars) or ('-' in earlier_4_chars) or ('-' in later_4_chars) or \n",
    "                ('(' in earlier_4_chars) or ('(' in later_4_chars) or (')' in earlier_4_chars) or \n",
    "                (')' in later_4_chars) or ('in' in earlier_4_chars) or ('in' in later_4_chars)\n",
    "                or (\"'\" in earlier_4_chars) or (\"'\" in later_4_chars)):\n",
    "                if temp_loc_of_chars<=250:\n",
    "                    dict_counts_normal[m] += 25\n",
    "                else:\n",
    "                    dict_counts_normal[m] += 5\n",
    "                    \n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            if (temp_loc_of_chars <=20):\n",
    "                dict_counts_normal[m] += 17\n",
    "            if (temp_loc_of_chars>20 and temp_loc_of_chars<=100):\n",
    "                dict_counts_normal[m] += 10\n",
    "            if (temp_loc_of_chars>100 and temp_loc_of_chars<=250):\n",
    "                dict_counts_normal[m] += 7\n",
    "            if (temp_loc_of_chars>=250 and temp_loc_of_chars<=1000):\n",
    "                dict_counts_normal[m] += 5\n",
    "            if (temp_loc_of_chars>1000):\n",
    "                dict_counts_normal[m] += 2\n",
    "                \n",
    "            if ('in' in earlier_3_chars): \n",
    "                if (temp_loc_of_chars<=50):\n",
    "                    dict_counts_normal[m] += 25\n",
    "                elif temp_loc_of_chars>50 and temp_loc_of_chars<=100:\n",
    "                    dict_counts_normal[m] += 20\n",
    "                elif temp_loc_of_chars>100 and temp_loc_of_chars<=250:\n",
    "                    dict_counts_normal[m] += 15\n",
    "\n",
    "            \"\"\"\n",
    "            if (conditions_to_check==True):\n",
    "                print('ps3190', m)\n",
    "                dict_counts_normal[m] += 3\n",
    "            \"\"\"\n",
    "            \n",
    "    city_names_normal_counts = list(dict_counts_normal.values())\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    city_names_indian = []\n",
    "    #city_names_indian_counts = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(0,len(indian_cities_sorted_by_count)):\n",
    "        city_names_indian.append(indian_cities_sorted_by_count[j][0])\n",
    "        #city_names_indian_counts.append(indian_cities_sorted_by_count[j][1]['count'])\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    dict_counts_indian = {}\n",
    "    for m in range(0, len(city_names_indian)):\n",
    "        dict_counts_indian[m] = 0\n",
    "\n",
    "    for m in range(0, len(city_names_indian)):\n",
    "        for p in range(0, len(list_preds[i]['indian_cities'][city_names_indian[m]]['span_info'])):\n",
    "            temp_loc_of_chars = list_preds[i]['indian_cities'][city_names_indian[m]]['span_info'][p][0]\n",
    "            \n",
    "            temp_loc_of_chars_end = list_preds[i]['indian_cities'][city_names_indian[m]]['span_info'][p][1]\n",
    "            \n",
    "            earlier_3_chars = df['cleaned_text'][i][temp_loc_of_chars-3:temp_loc_of_chars]\n",
    "            later_2_chars = df['cleaned_text'][i][temp_loc_of_chars_end:temp_loc_of_chars_end+2]\n",
    "            \n",
    "            \n",
    "            if temp_loc_of_chars<20:\n",
    "                    later_and_before_20_chars = df['cleaned_text'][i][0:temp_loc_of_chars_end+20]\n",
    "            if temp_loc_of_chars>=20:\n",
    "                    later_and_before_20_chars = df['cleaned_text'][i][temp_loc_of_chars-20:temp_loc_of_chars_end+20]\n",
    "            \n",
    "                        \n",
    "            check_if_month_present = [ele for ele in months if(ele in later_and_before_20_chars)] \n",
    "            \n",
    "            \n",
    "            conditions_to_check = (check_if_month_present!=[] and temp_loc_of_chars<=250)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print('conditions satisfied?', conditions_to_check)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            if ((',' in earlier_4_chars) or (',' in later_4_chars) or (':' in earlier_4_chars)\n",
    "                or (':' in later_4_chars) or ('-' in earlier_4_chars) or ('-' in later_4_chars) or \n",
    "                ('(' in earlier_4_chars) or ('(' in later_4_chars) or (')' in earlier_4_chars) or \n",
    "                (')' in later_4_chars) or ('in' in earlier_4_chars) or ('in' in later_4_chars)\n",
    "                or (\"'\" in earlier_4_chars) or (\"'\" in later_4_chars)):\n",
    "                if temp_loc_of_chars<=250:\n",
    "                    dict_counts_indian[m] += 25\n",
    "                else:\n",
    "                    dict_counts_indian[m] += 5\n",
    "                    \n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            if (temp_loc_of_chars<=20):\n",
    "                dict_counts_indian[m] += 17\n",
    "            if (temp_loc_of_chars>20 and temp_loc_of_chars<=100):\n",
    "                dict_counts_indian[m] += 10\n",
    "            if (temp_loc_of_chars>100 and temp_loc_of_chars<=250):\n",
    "                dict_counts_indian[m] += 7\n",
    "            if (temp_loc_of_chars>=250 and temp_loc_of_chars<=1000):\n",
    "                dict_counts_indian[m] += 5\n",
    "            if (temp_loc_of_chars>1000):\n",
    "                dict_counts_indian[m] += 2\n",
    "            \n",
    "            \"\"\"\n",
    "            if (conditions_to_check==True):\n",
    "                print('ps3190', m)\n",
    "                dict_counts_indian[m] += 3\n",
    "            \"\"\"\n",
    "            \n",
    "            if ('in' in earlier_3_chars): \n",
    "                if (temp_loc_of_chars<=50):\n",
    "                    dict_counts_indian[m] += 25\n",
    "                elif temp_loc_of_chars>50 and temp_loc_of_chars<=100:\n",
    "                    dict_counts_indian[m] += 20\n",
    "                elif temp_loc_of_chars>100 and temp_loc_of_chars<=250:\n",
    "                    dict_counts_indian[m] += 15\n",
    "\n",
    "\n",
    "    city_names_indian_counts = list(dict_counts_indian.values())\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "    common_names = common_member(city_names_normal_from_listpreds, city_names_indian)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print('listpred normal cities: ', city_names_normal_from_listpreds)\n",
    "    #print('normal counts: ', city_names_normal_counts)\n",
    "    #print('indian cities: ', city_names_indian)\n",
    "    #print('indian counts: ', city_names_indian_counts)\n",
    "    #print('countries:', countries_names)\n",
    "    #print('countries counts:', countries_counts)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    city_names_normal = city_names_normal_from_listpreds\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(common_names) > 0:\n",
    "        try:\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print('c111')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            max_counts = {}\n",
    "            for j in range(0,len(common_names)):\n",
    "                normal_count = city_names_normal_counts[city_names_normal.index(common_names[j])]\n",
    "                indian_count = city_names_indian_counts[city_names_indian.index(common_names[j])]\n",
    "                max_counts[common_names[j]] = max(normal_count, indian_count)\n",
    "\n",
    "            for j in range(0,len(common_names)):\n",
    "                del city_names_normal_counts[(city_names_normal.index(common_names[j]))]\n",
    "                city_names_normal.remove(common_names[j])\n",
    "\n",
    "            sentence_of_cities = ''\n",
    "            for key, value in max_counts.items():\n",
    "                #print('Common to normal and Indian cities:',key, value)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #replacing the actual Indian city name with Mumbai because geotext doesn't recognise the real city name\n",
    "                sentence_of_cities += ('Mumbai'+' and ')*value\n",
    "            #print('\\nRemaining in normal:')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            for j in range(0, len(city_names_normal)):\n",
    "                #print(city_names_normal[j], city_names_normal_counts[j])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "                \n",
    "                \"\"\"\n",
    "                if city_names_normal[j] != 'Hong Kong':\n",
    "                    sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "                else:\n",
    "                    #sentence_of_cities += (city_names_normal[j] +' and ')*math.floor(city_names_normal_counts[j]/2)\n",
    "                    sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "\n",
    "                \"\"\"\n",
    "            countries_mentioned1 = GeoText2(sentence_of_cities).country_mentions\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            for k in range(0, len(countries_sorted_by_count)):\n",
    "                temp_k_countrynames.append(countries_sorted_by_count[k][0])\n",
    "                temp_k_countrycount.append(countries_sorted_by_count[k][1]['count'])\n",
    "                \n",
    "            \"\"\"                \n",
    "                \n",
    "                        \n",
    "            temp_k_sentence = ''\n",
    "            for k in range(0,len(countries_names)):\n",
    "                temp_k_sentence += (countries_names[k]+' and ')*countries_counts[k]\n",
    "            \n",
    "            d1 = GeoText2(temp_k_sentence).country_mentions\n",
    "            #print(d1)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            d2 = countries_mentioned1\n",
    "            #d2.update(d1)\n",
    "            result = sorted(list(d1.items()) + list(d2.items()))\n",
    "\n",
    "            #countries_from_cities[i] = d2\n",
    "            countries_from_cities[i] = result\n",
    "            #print(i, countries_mentioned, '\\n')\n",
    "            #print(i, d2, '\\n')\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print('COUNTRIES2: ', countries_from_cities[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(i, result, '\\n')\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    else:  \n",
    "        if len(city_names_normal)==0:\n",
    "            try:\n",
    "                \n",
    "                \n",
    "                #print('b111')\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                sentence_of_cities = ''\n",
    "                for j in range(0,len(city_names_indian)):\n",
    "                    #print(city_names_indian[j], city_names_indian_counts[j])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #replacing the actual Indian city name with Mumbai because geotext doesn't recognise the real city name\n",
    "                    sentence_of_cities += ('Mumbai'+' and ')*city_names_indian_counts[j]\n",
    "\n",
    "                countries_mentioned2 = GeoText2(sentence_of_cities).country_mentions\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                for k in range(0, len(countries_sorted_by_count)):\n",
    "                    temp_k_countrynames.append(countries_sorted_by_count[k][0])\n",
    "                    temp_k_countrycount.append(countries_sorted_by_count[k][1]['count'])\n",
    "                \n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                temp_k_sentence = ''\n",
    "                for k in range(0,len(countries_names)):\n",
    "                    temp_k_sentence += (countries_names[k]+' and ')*countries_counts[k]\n",
    "\n",
    "                d1 = GeoText2(temp_k_sentence).country_mentions\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print(d1)\n",
    "                d2 = countries_mentioned2\n",
    "                #d2.update(d1)\n",
    "                result = sorted(list(d1.items()) + list(d2.items()))\n",
    "                \n",
    "                #countries_from_cities[i] = countries_mentioned\n",
    "                #countries_from_cities[i] = d2\n",
    "                countries_from_cities[i] = result\n",
    "                #print(i, countries_mentioned, '\\n')\n",
    "                #print(i, d2, '\\n')\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print('COUNTRIES5:', countries_from_cities[i])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print(i, result, '\\n')\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if len(city_names_indian) == 0:\n",
    "            try:\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print('a111')\n",
    "                \n",
    "                \n",
    "                \n",
    "                sentence_of_cities = ''\n",
    "                for j in range(0, len(city_names_normal_from_listpreds)):\n",
    "                    #print(city_names_normal_from_listpreds[j], city_names_normal_counts[j])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "                    \n",
    "                    \"\"\"\n",
    "                    if city_names_normal[j] != 'Hong Kong':\n",
    "                        sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "                    else:\n",
    "                        sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "                        #sentence_of_cities += (city_names_normal[j] +' and ')*math.floor(city_names_normal_counts[j]/2)\n",
    "                    \"\"\"\n",
    "                \n",
    "                #print('countries_names1111',countries_names)\n",
    "                \n",
    "                \n",
    "                \n",
    "                #print('Sentence of d2:', sentence_of_cities)\n",
    "\n",
    "                countries_mentioned3 = GeoText2(sentence_of_cities).country_mentions\n",
    "                #print('countries_mentioned3: ', countries_mentioned3)\n",
    "                                \n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                for k in range(0, len(countries_sorted_by_count)):\n",
    "                    temp_k_countrynames.append(countries_sorted_by_count[k][0])\n",
    "                    temp_k_countrycount.append(countries_sorted_by_count[k][1]['count'])\n",
    "                    \n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "\n",
    "                temp_k_sentence = ''\n",
    "                for k in range(0,len(countries_names)):\n",
    "                    temp_k_sentence += (countries_names[k]+' and ')*countries_counts[k]\n",
    "\n",
    "                                \n",
    "                \n",
    "                \n",
    "                d1 = GeoText2(temp_k_sentence).country_mentions\n",
    "                #print('d1: ', d1)\n",
    "                d2 = countries_mentioned3\n",
    "                print('d2: ', d2)\n",
    "                #d2.update(d1)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                result = sorted(list(d1.items()) + list(d2.items()))\n",
    "                \n",
    "                #countries_from_cities[i] = countries_mentioned\n",
    "                #countries_from_cities[i] = d2\n",
    "                countries_from_cities[i] = result\n",
    "                #print(i, countries_mentioned, '\\n')\n",
    "                #print(i, d2, '\\n')\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print('COUNTRIES9:', countries_from_cities[i])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print(i, result, '\\n')\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "        if ((len(city_names_normal)>0) and (len(city_names_indian)>0)):\n",
    "            try:\n",
    "                \n",
    "                \n",
    "                \n",
    "                #print('d111')\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                sentence_of_cities = ''\n",
    "                \n",
    "                for j in range(0,len(city_names_indian)):\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #print(city_names_indian[j], city_names_indian_counts[j])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    #replacing the actual Indian city name with Mumbai because geotext doesn't recognise the real city name\n",
    "                    sentence_of_cities += ('Mumbai'+' and ')*city_names_indian_counts[j]\n",
    "                \n",
    "                for j in range(0, len(city_names_normal)):\n",
    "                    print(city_names_normal[j], city_names_normal_counts[j])\n",
    "                    \n",
    "                    \n",
    "                    sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "                    \"\"\"\n",
    "                    if city_names_normal[j] != 'Hong Kong':\n",
    "                        sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "                    else:\n",
    "                        sentence_of_cities += (city_names_normal[j] +' and ')*city_names_normal_counts[j]\n",
    "                        #sentence_of_cities += (city_names_normal[j] +' and ')*math.floor(city_names_normal_counts[j]/2)\n",
    "                    \"\"\"\n",
    "                \n",
    "                \n",
    "                #print('Sentence of cities for d2:', sentence_of_cities)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                countries_mentioned4 = GeoText2(sentence_of_cities).country_mentions\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                for k in range(0, len(countries_sorted_by_count)):\n",
    "                    temp_k_countrynames.append(countries_sorted_by_count[k][0])\n",
    "                    temp_k_countrycount.append(countries_sorted_by_count[k][1]['count'])\n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "                temp_k_sentence = ''\n",
    "                for k in range(0,len(countries_names)):\n",
    "                    temp_k_sentence += (countries_names[k]+' and ')*countries_counts[k]\n",
    "                 \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print('temp_k_sentence for d1:', temp_k_sentence)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                d1 = GeoText2(temp_k_sentence).country_mentions\n",
    "                d2 = countries_mentioned4\n",
    "                \n",
    "                \n",
    "                #print('d1:',d1)\n",
    "                #print('d2:',d2)\n",
    "                \n",
    "                \n",
    "                \n",
    "                #d2.update(d1)\n",
    "                result = sorted(list(d1.items()) + list(d2.items()))\n",
    "  \n",
    "                #countries_from_cities[i] = result\n",
    "\n",
    "                \n",
    "                #countries_from_cities[i] = countries_mentioned\n",
    "                #print(i, countries_mentioned, '\\n')\n",
    "                \n",
    "                #countries_from_cities[i] = d2\n",
    "                countries_from_cities[i] = result\n",
    "                #print(i, d2, '\\n')\n",
    "                \n",
    "                \n",
    "                \n",
    "                #print('COUNTRIES4:', countries_from_cities[i])\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                #print(i, result, '\\n')\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#city_names_normal_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addCity2(city_list, countrycode):\n",
    "    \n",
    "    dict_counts_countryname = 'dict_counts_' + countrycode.lower()\n",
    "    city_names_countryname = 'city_names_' + countrycode.lower()\n",
    "    countryname_with_city = countrycode.lower() +'_cities'\n",
    "    city_names_countryname_counts = 'city_names_' + countrycode.lower() + '_counts'\n",
    "\n",
    "        \n",
    "    for i in range(0, end_of_range):\n",
    "        \n",
    "        city_names_countryname = list(list_preds[i][countryname_with_city].keys())\n",
    "        \n",
    "        \n",
    "\n",
    "        dict_counts_countryname = {}\n",
    "        for m in range(0, len(city_names_countryname)):\n",
    "            dict_counts_countryname[m] = 0\n",
    "            \n",
    "            \n",
    "            \n",
    "        #if city_names_countryname != []:\n",
    "            #print(i, city_names_countryname)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        for m in range(0, len(city_names_countryname)):\n",
    "            for p in range(0, len(list_preds[i][countryname_with_city][city_names_countryname[m]]['span_info'])):\n",
    "                \n",
    "                temp_loc_of_chars = list_preds[i][countryname_with_city][city_names_countryname[m]]['span_info'][p][0]\n",
    "                \n",
    "                temp_loc_of_chars_end = list_preds[i][countryname_with_city][city_names_countryname[m]]['span_info'][p][1]\n",
    "            \n",
    "                earlier_3_chars = df['cleaned_text'][i][temp_loc_of_chars-3:temp_loc_of_chars]\n",
    "                later_2_chars = df['cleaned_text'][i][temp_loc_of_chars_end:temp_loc_of_chars_end+2]\n",
    "                if temp_loc_of_chars<20:\n",
    "                    later_and_before_20_chars = df['cleaned_text'][i][0:temp_loc_of_chars_end+20]\n",
    "                if temp_loc_of_chars>=20:\n",
    "                    later_and_before_20_chars = df['cleaned_text'][i][temp_loc_of_chars-20:temp_loc_of_chars_end+20]\n",
    "                \n",
    "                check_if_month_present = [ele for ele in months if(ele in later_and_before_20_chars)] \n",
    "\n",
    "                conditions_to_check = (check_if_month_present!=[] and temp_loc_of_chars<=250)\n",
    "            \n",
    "                #print('conditions satisfied?', conditions_to_check)\n",
    "\n",
    "               \n",
    "                \n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                if ((',' in earlier_4_chars) or (',' in later_4_chars) or (':' in earlier_4_chars)\n",
    "                    or (':' in later_4_chars) or ('-' in earlier_4_chars) or ('-' in later_4_chars) or \n",
    "                    ('(' in earlier_4_chars) or ('(' in later_4_chars) or (')' in earlier_4_chars) or \n",
    "                    (')' in later_4_chars) or ('in' in earlier_4_chars) or ('in' in later_4_chars)\n",
    "                    or (\"'\" in earlier_4_chars) or (\"'\" in later_4_chars)):\n",
    "                    if temp_loc_of_chars<=250:\n",
    "                        dict_counts_countryname[m] += 20\n",
    "                    else:\n",
    "                        dict_counts_countryname[m] += 5\n",
    "                        \n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "                if (temp_loc_of_chars<=20):\n",
    "                    dict_counts_countryname[m] += 17\n",
    "                if (temp_loc_of_chars>20 and temp_loc_of_chars<=100):\n",
    "                    dict_counts_countryname[m] += 10\n",
    "                if (temp_loc_of_chars>100 and temp_loc_of_chars<=250):\n",
    "                    dict_counts_countryname[m] += 8\n",
    "                if (temp_loc_of_chars>=250 and temp_loc_of_chars<=1000):\n",
    "                    dict_counts_countryname[m] += 2\n",
    "                if (temp_loc_of_chars>1000):\n",
    "                    dict_counts_countryname[m] += 1\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                if (conditions_to_check==True):\n",
    "                    dict_counts_countryname[m] += 3\n",
    "               \n",
    "                \n",
    "                if ('in' in earlier_3_chars): \n",
    "                    if (temp_loc_of_chars<=50):\n",
    "                        dict_counts_countryname[m] += 25\n",
    "                    elif temp_loc_of_chars>50 and temp_loc_of_chars<=100:\n",
    "                        dict_counts_countryname[m] += 20\n",
    "                    elif temp_loc_of_chars>100 and temp_loc_of_chars<=250:\n",
    "                        dict_counts_countryname[m] += 15\n",
    "\n",
    "        city_names_countryname_counts = list(dict_counts_countryname.values())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #if city_names_countryname_counts != []:\n",
    "            #print(city_names_countryname_counts)\n",
    "        \n",
    "        \n",
    "\n",
    "        if (city_names_countryname_counts != []) :\n",
    "            for j in range(0, len(city_names_countryname)):\n",
    "                try:                    \n",
    "                    #print(i, city_list[j], city_names_countryname_counts[j])\n",
    "                    countries_from_cities[i].append(tuple([countrycode, city_names_countryname_counts[j]]))\n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        #if (city_names_countryname_counts != []) :\n",
    "            #print(i, countries_from_cities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(0, len(df)):\n",
    "    if (list_preds[i]['EU_cities'] != {}):\n",
    "        try:\n",
    "            if (list_preds[i]['EU_cities']['European Union']['count'] > 0 and (list_preds[i]['EU_cities']['EU']['count'] > 0)):\n",
    "                countries_from_cities[i].append(('EU', list_preds[i]['EU_cities']['EU']['count'] + list_preds[i]['EU_cities']['European Union']['count']))\n",
    "            else:\n",
    "                try:\n",
    "                    if (list_preds[i]['EU_cities']['European Union']['count'] > 0):\n",
    "                        countries_from_cities[i].append(list_preds[i]['EU_cities']['European Union']['count'])\n",
    "                except:\n",
    "                    countries_from_cities[i].append(list_preds[i]['EU_cities']['EU']['count'])\n",
    "        except:\n",
    "            pass\n",
    "\"\"\"\n",
    "addCity2([\"Stjohns\"],'AG17')\n",
    "addCity2([\"St. George's\"],'GD17')\n",
    "addCity2([\"Portofspain\"],'TT17')\n",
    "addCity2([\"Malé\"],'MV17')\n",
    "addCity2([\"Nuku'alofa\",'Nukualofa'],'TO17')\n",
    "addCity2([\"BSE\",'Bse','B.S.E.','B.s.e.','Rbi','RBI','Cbi','Cid','CBI','CID'],'IN17')\n",
    "addCity2(['Kempegowda Nagar','Kempegowdanagar','Perambur','Vallanadu','Thoothukudi','Bombay Stock Exchange','Kashmir','Erragadda','Nagapattinam','Nagappattinam','Taj Mahal','Tiruchi','Bollywood','Keerapakkam', 'Tambaram','Kannada','Indrakeeladri','Dhinkia','Havelock Island'],'IN18')\n",
    "\n",
    "\n",
    "addCity2(['Hobart','Sydney','Perth','Melbourne','NSW','New South Wales','Queensland','Tuggeranong','Bondi Beach','Flemington','Warracknabeal','Tasmania','Belconnen','Lesmurdie','Donvale','Weetangera','Lancefield', 'Cobaw', 'Benloch', 'Pastoria', 'Baynton','Saint George','St George','Kogarah','Victoria'], 'AUX')\n",
    "addCity2(['Dhaka'], 'BDX')\n",
    "addCity2(['Athens','Moria'], 'GRX')\n",
    "addCity2(['Jalalabad','Kandahar','Herat'], 'AFX')\n",
    "addCity2(['Paris','Lyon','Dordogne','Stade de France'], 'FRX')\n",
    "addCity2(['Niger Delta','Borno','Nigeria','Lagos','Ogun'],'NGX')\n",
    "addCity2(['EU','European Union','E.U.','Eu','European Commission','European Investment Bank','Euro','euro'], 'EUX')\n",
    "addCity2(['UN','United Nations','U.N.','Un'], 'UNX')\n",
    "addCity2(['Bali'],'IDX')\n",
    "addCity2(['Damascus'],'SYX')\n",
    "addCity2(['Santa Maria','Rio Olympic','Rio Olympics','Rio 2016'],'BRX')\n",
    "addCity2(['Moscow','Saint Petersburg','St. Petersburg'],'RUX')\n",
    "addCity2(['Newengland','Albany','Tippecanoe','St. Augustine','Vilano Beach','St. Tammany','District of Columbia','Bryant Park','Charlotte','Boro Park','Roseburg','Marrero','Montauk','Long Island','Capitol Hill','Syracuse','Georgetown','New Smyrna Beach','Palm Beach','St. Louis','North Little Rock','Port Saint Lucie','Central Park','America','Queens','Lawrence','Williamsburg','Washington','Washington, D.C.','Prairie View','Santa Clara', 'San Jose', 'Santa Cruz', 'Hudson Valley','Kitsap County','Harvard','Mount Sinai','Putnam County','Goddard Park',\"Hawai'i\",'Davis','Calaveras County','Wall Street','Carroll County','Humboldt County','Neshannock','Penn','Yale','Federal Reserve','NYC','N.Y.C.','San Francisco', 'San Mateo','Worcester','Johnson City','Cdc','Harlem','NYPD','St Louis','Fox Lake','Pentagon','Richmond','Telluride','White House'],'USX1')\n",
    "addCity2(['Usa','Dow','Buffalo','BUFFALO','Democrat','Democrats','Republican','Republicans','Senator','FBI','Fbi','F.B.I.','Us','Nasa','NASA','Sen.','Fed','GOP','Gop','Centers for Disease Control and Prevention'],'USX2')\n",
    "addCity2(us_state_names,'US11')\n",
    "addCity2(['Haiti','Portauprince'],'HTX')\n",
    "addCity2(['Mali'],'MLX')\n",
    "addCity2(['Cabo Delgado', 'Ancuabe', 'Mozambique'],'MZX')\n",
    "addCity2(['Pama'],'BFX')\n",
    "addCity2(['Papuanewguinea'],'PGX')\n",
    "addCity2(['Grimsby', 'Lincolnshire','Widnes','Middlesex','Cambridge','Oxford','London','Ascension Island','Newcastle','British','Somerset','Bristol','Carterton','Derbyshire','West Hampstead','Romsey','Tottenham','Sky Sports','West Hampstead','Kent','Brighton','Cornwall','Westminster','Boosbeck','Yorkshire','Chelsea','Manchester','Norwich','Norfolk','Birmingham', 'England', 'Wales', 'Northern Ireland', 'Scotland','Manchester','Richmond and Twickenham','Britain','Clogher','Wandsworth','Cronton','Inverurie','Peak District', 'Snowdonia', 'Dorset','Dundee','Salisbury','Suffolk'],'GBX3')\n",
    "addCity2(['Uk','Gbr','GBR','Boris Johnson','NHS','Nhs','nhs','£'],'GBX4')\n",
    "addCity2(['Vigui'],'PAX')\n",
    "addCity2(['Somalia'],'SO11')\n",
    "addCity2(['Wellington','Albert Town','Queenstown','Napier','Waitarere','Levin'],'NZ11')\n",
    "addCity2(['Frankfurt','Nürnberg','Nuremberg','Cologne','Jena','Melle','Achim','Auerbach'],'DE11')\n",
    "addCity2(['Venice','Milan','San Siro','San Donato Milanese'],'IT11')\n",
    "addCity2(['Vienna','Nickelsdorf','Sölden','Soelden'],'AT11')\n",
    "addCity2(['Syria','Idlib'],'SY11')\n",
    "addCity2(['Yemen','Mokha','Mocha',\"Sa'dah\",'Saada'],'YE11')\n",
    "addCity2(['Vernon','Trans Mountain','TransMountain','Newfoundland','Labrador','Harrison Hot Springs','Victoria'],'CA11')\n",
    "addCity2(['Tiananmen Square','Guangdong','Peking','Urumqi',\"Xi’an\",\"Xi'an\",'Xian','Jiangsu','Hunan','Kashgar'],'CN11')\n",
    "addCity2(['Roszke'],'HU11')\n",
    "addCity2(['El Salvador'],'SV11')\n",
    "addCity2(['DRC','Kasai','Drc'],'CD11')\n",
    "addCity2(['Rcongo'],'CG11')\n",
    "addCity2(['Naguru','Kampala','Uganda','Entebbe'],'UG11')\n",
    "addCity2(['Cotopaxi','Ecuador'],'EC11')\n",
    "addCity2(['Jerusalem','Hadera','Yerushalayim','Bnei Brak','Safed'],'IL11')\n",
    "addCity2(['Duma','Hamas','Eastjerusalem'],'PS11')\n",
    "addCity2(['Cyprus'],'CY11')\n",
    "addCity2(['Santo Domingo','Dominican Republic'],'DO11')\n",
    "addCity2(['Chiang Mai'],'TH11')\n",
    "addCity2(['Holland','Nederland'],'NL12')\n",
    "addCity2(['Bermuda'],'BM11')\n",
    "addCity2(['Kim Jong Un','DPRK','Dprk','D.P.R.K.'],'KP11')\n",
    "addCity2(['Tenerife','Canary Islands','Barcelona','Catalonia'],'ES11')\n",
    "addCity2(['Tshwane','Limpopo','Maritzburg','Mankweng','Manenberg','Ficksburg','Bellville','Ekurhuleni','Suikerbosrand','Eastern Cape','Western Cape','De Doorns','Daveyton','Gauteng','De Deur','Nongoma','Khayelitsha','Modderpoort','Free State','Mafikeng','Mosselbay','Mossel Bay','Pollsmoor','Tlokwe','Brandfort','Boikhutso', 'Welgevonden', 'Goedgevonden','Kakamas','Sterkspruit', 'Engcobo','Ngcobo', 'Gugwini', 'Silindile', 'Moyeni'],'ZA11')\n",
    "addCity2(['Mahé','Seychelles'],'SC11')\n",
    "addCity2(['Gorgan','Golestan','Tehran','Bandar Abbas'],'IR11')\n",
    "addCity2(['Qatar'],'QA11')\n",
    "addCity2(['Zurich','Geneva'],'CH11')\n",
    "addCity2(['Sint Maarten','St. Maarten','St Maarten'],'SX11')\n",
    "addCity2(['UAE','Uae','U.A.E.'],'AE11')\n",
    "addCity2(['Bahamas'],'BS11')\n",
    "addCity2(['Hanoi','Ha Noi', 'Vu Duc Dam','Ho Chi Mihn City','Hà Nội'],'VN11')\n",
    "addCity2(['Gothenburg','Sweden'],'SE11')\n",
    "addCity2(['Muranga'],'KE11')\n",
    "addCity2(['Belize','Bdf'],'BZ11')\n",
    "addCity2(['Antarctica'],'AQ11')\n",
    "addCity2(['Niger'],'NE11')\n",
    "addCity2(['Murilo'],'FM11')\n",
    "addCity2(['Fukushima','Omura','Fukuoka'],'JP11')\n",
    "addCity2(['Porto'],'PT11')\n",
    "addCity2(['Apia','Samoa'],'WS')\n",
    "addCity2(['Libya'],'LY11')\n",
    "addCity2(['Istanbul'],'TR11')\n",
    "addCity2(['Fiji'],'FJ11')\n",
    "addCity2(['Nuuk','Greenland'],'GL11')\n",
    "addCity2(['Tajikistan'],'TJ11')\n",
    "addCity2(['Uzbekistan'],'UZ11')\n",
    "addCity2(['Auki', 'Solomon Islands'],'SB11')\n",
    "addCity2(['Chernobyl'],'UA11')\n",
    "addCity2(['Hong KONG'],'HK12')\n",
    "addCity2(['Malta'],'MT11')\n",
    "addCity2(['Namibia'],'NAX11')\n",
    "addCity2(['Bosnia-Herzegovina'],'BA11')\n",
    "addCity2(['Dominica'],'DM11')\n",
    "addCity2(['Togo'],'TG11')\n",
    "addCity2(['St. Peter’s Square', 'Saint Peter’s Square','St. Peter’s Basilica','Saint Peter’s Basilica'],'VA11')\n",
    "addCity2(['Ashanti Region','Ho Municipal','Ho Municipality'],'GH11')\n",
    "addCity2(['Praia'],'CV11')\n",
    "\n",
    "addCity2([\"dharna\",'Dharna'],'IN19')\n",
    "addCity2(['Mullaitivu'],'LK14')\n",
    "addCity2(['Mexicocity'],'MX14')\n",
    "addCity2(['Sierra Leone'],'SL14')\n",
    "addCity2(['Porto-Novo','Porto Novo','Portonovo'],'BJ14')\n",
    "\n",
    "\n",
    "addCity2(['San José'],'CR14')\n",
    "addCity2([\"Stgeorges\"],'GD14')\n",
    "addCity2([\"Chisinau\"],'MD14')\n",
    "addCity2([\"Victoria\"],'SC14')\n",
    "addCity2([\"Juba\"],'SS14')\n",
    "addCity2([\"Sri Jayawardenapura Kotte\"],'LK15')\n",
    "addCity2(['George Town'],'MY15')\n",
    "\n",
    "\n",
    "addCity2(can_provinces, 'CA17')\n",
    "\n",
    "addCity2(['Balochistan', 'Khyber Pakhtunkhwa', 'Sindh'],'PK11')\n",
    "\n",
    "\n",
    "addCity2(can_abbreviations2, 'CA18')\n",
    "addCity2(['Killarney','Dublin'], 'IE11')\n",
    "addCity2(['Saint Joseph','St. Joseph'], 'TT11')\n",
    "addCity2(['Hong Kong','HK','H.K.','Causeway Bay','Mong Kok','Lung Wo Road'], 'HK11')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "addCity2(['Angola'],'AO21')\n",
    "addCity2(['Antigua and Barbuda','Antigua & Barbuda','Antigua','Barbuda'],'AG21')\n",
    "addCity2(['Bosnia and Herzegovina','Bosnia & Herzegovina','Bosnia','Herzegovina'],'BA21')\n",
    "addCity2(['EquatorialGuinea'],'GQ21')\n",
    "addCity2(['Eritrea'],'ER21')\n",
    "addCity2(['Gambia'],'GM21')\n",
    "addCity2(['Granada'],'NI21')\n",
    "addCity2(['Guinea'],'GN21')\n",
    "addCity2(['Honduras'],'HN21')\n",
    "addCity2(['Liechtenstein'],'LI21')\n",
    "addCity2(['Macedonia'],'MK21')\n",
    "addCity2(['Marshallislands'],'MH21')\n",
    "addCity2(['Mauritius'],'MU21')\n",
    "addCity2(['Micronesia'],'FM21')\n",
    "addCity2(['Mongolia'],'MN21')\n",
    "addCity2(['Nicaragua'],'NI21')\n",
    "addCity2(['Palestine'],'PS21')\n",
    "addCity2(['Paraguay'],'PY21')\n",
    "addCity2(['Senegal'],'SN21')\n",
    "addCity2(['Swaziland'],'SZ21')\n",
    "addCity2(['Turkmenistan'],'TM21')\n",
    "addCity2(['Uruguay'],'UY21')\n",
    "addCity2(['Saintkittsandnevis'],'KN21')\n",
    "addCity2(['Saintlucia'],'LC21')\n",
    "addCity2(['Saintvincentandthegrenadines'],'VC21')\n",
    "addCity2(['Southsudan'],'SS21')\n",
    "addCity2(['Trinidadandtobago'],'TT21')\n",
    "addCity2(['Unitedarabemirates'],'AE21')\n",
    "addCity2(['Guineabissau','Bissau'],'GW21')\n",
    "addCity2(['Georgia'],'GE21')\n",
    "addCity2(['Britishcolumbia'],'CA21')\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(missing_countries)):\n",
    "    addCity2([str(missing_countries_names[missing_countries[i]]), \n",
    "             str(missing_countries_capitals[missing_countries[i]])], missing_countries[i].lower()+'XC13')\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,len(plural_nationalities)):\n",
    "    try:\n",
    "        #print(i, plural_nationalities['country_code'][i])\n",
    "        addCity2(getPlural(plural_nationalities['plural_country'][i]), plural_nationalities['country_code'][i]+'YC'+str(i))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_country = {}\n",
    "pred_country_list = {}\n",
    "#for i in range(0,len(df)):\n",
    "    \n",
    "for i in range(0,end_of_range):\n",
    "    try:\n",
    "        #pred_country[i] = max(countries_from_cities[i], key=len)\n",
    "        try:\n",
    "            pred_country[i] = list(OrderedDict(sorted(countries_from_cities[i].items(), key=lambda t: t[1])))[-1]\n",
    "            print(i)  # Prints nothing\n",
    "        except:\n",
    "            #pred_country[i] = countries_from_cities[i][::-1][-1][0]\n",
    "            pred_country[i] = Sort_Tuple(countries_from_cities[i])[-1][0]\n",
    "        pred_country_list[i] = countries_from_cities[i]\n",
    "    except:\n",
    "        pred_country[i] = ''\n",
    "        pred_country_list[i] = ''\n",
    "        \n",
    "for i in range(end_of_range, len(df)):\n",
    "    pred_country[i] = ''\n",
    "    pred_country_list[i] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['pred_country_list_flashgeotext'] = list(pred_country_list.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_states = ['SG','VA','MC']\n",
    "pred_country_max = []\n",
    "pred_country_list_max = []\n",
    "#for i in range(0,len(df)):\n",
    "\n",
    "for i in range(0,end_of_range):\n",
    "    \n",
    "    temp1 = df['pred_country_list_flashgeotext'][i]\n",
    "    temp1_list = list(dict(temp1).keys())\n",
    "    temp1_list_counts = {}\n",
    "\n",
    "    for m in range(0,len(temp1_list)):\n",
    "        temp1_list_counts[temp1_list[m]] = 0\n",
    "\n",
    "    for m in range(0, len(temp1_list)):\n",
    "        for j in range(0,len(temp1)):\n",
    "            if (temp1_list[m][0:2] == temp1[j][0][0:2]):\n",
    "                if (temp1_list[m][0:2] not in city_states):\n",
    "                    temp1_list_counts[temp1_list[m]] += temp1[j][1]\n",
    "                else:\n",
    "                    temp1_list_counts[temp1_list[m]] = temp1[j][1]\n",
    "    \n",
    "    try:\n",
    "        output_scores = list(dict(sorted(temp1_list_counts.items(), key=lambda t: t[1])).values())\n",
    "        max_output = output_scores[-1]\n",
    "        for j in range(0,len(output_scores)):\n",
    "            output_scores[j] = output_scores[j] - max_output\n",
    "            \n",
    "        output_scores_countries = []\n",
    "        for j in range(0,len(output_scores)):\n",
    "            if output_scores[j]==0:\n",
    "                output_scores_countries.append(list(OrderedDict(sorted(temp1_list_counts.items(), key=lambda t: t[1])))[j])\n",
    "        \n",
    "        temp_list_pred_countries = output_scores_countries\n",
    "        temp_list_pred_countries2 = []\n",
    "        for j in temp_list_pred_countries:\n",
    "            temp_list_pred_countries2.append(j.replace(\" \",\"\")[0:2])\n",
    "        temp_list_pred_countries2 = list(dict.fromkeys(temp_list_pred_countries2))\n",
    "        temp_list_pred_countries2 = list(dict.fromkeys(temp_list_pred_countries2))\n",
    "        pred_country_max.append(str(temp_list_pred_countries2).replace('\"','').replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").upper())\n",
    "        pred_country_list_max.append(OrderedDict(sorted(temp1_list_counts.items(), key=lambda t: t[1])))\n",
    "    except:\n",
    "        pred_country_max.append('')\n",
    "        pred_country_list_max.append([])\n",
    "        \n",
    "for i in range(end_of_range,len(df)):\n",
    "    pred_country_max.append('')\n",
    "    pred_country_list_max.append([])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_predicted_cities = []\n",
    "for j in range(0, end_of_range):\n",
    "    temp_list32 = list(list_preds[j].values())\n",
    "    temp_list32_nonzero = []\n",
    "    \n",
    "    for i in range(0,len(temp_list32)):\n",
    "        #print(i)\n",
    "        if temp_list32[i]!={}:\n",
    "            temp_list32_nonzero.append(temp_list32[i])\n",
    "    \n",
    "    temp_list32_nonzero_keys = []\n",
    "    for i in range(0,len(temp_list32_nonzero)):\n",
    "        temp_list32_nonzero_keys.extend(list(temp_list32_nonzero[i].keys()))\n",
    "    list_of_predicted_cities.append(temp_list32_nonzero_keys)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predicted_countries = []\n",
    "for i in range(0,len(df)):\n",
    "    temp_country_list = list(pred_country_max[i].split(', '))\n",
    "    temp_country_list = list(dict.fromkeys(temp_country_list))\n",
    "    final_predicted_countries.append(str(temp_country_list).replace('\"','').replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['pred_country_flashgeotext'] = final_predicted_countries\n",
    "df['pred_country_list_flashgeotext'] = pred_country_list_max\n",
    "df['pred_country_list_names'] = list_of_predicted_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#un-comment this next time\n",
    "\n",
    "#df2 = df[['url','cleaned_text','pred_country_flashgeotext','pred_country_list_flashgeotext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df2 = df[['url','cleaned_text','manual_country','pred_country_flashgeotext','pred_country_list_flashgeotext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df.loc[0:end_of_range-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_excel('covid news/v6/part1 pred.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('/Users/prajwal/Desktop/Koc/week5/v11/full.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "country_codes = pd.read_excel('country codes.xlsx')\n",
    "\n",
    "country_codes_dict = {}\n",
    "for i in range(0,len(country_codes)):\n",
    "    country_codes_dict[country_codes['country'][i]] = country_codes['code'][i]\n",
    "country_codes_dict['US'] = 'US'\n",
    "country_codes_dict['Sri'] = 'LK'\n",
    "country_codes_dict['Lanka'] = 'LK'\n",
    "country_codes_dict['Ukraine'] = 'UA'\n",
    "country_codes_dict['Philippine'] = 'PH'\n",
    "\n",
    "manual_country_code = {}\n",
    "for i in range(0,len(df2)):\n",
    "    #print(i)\n",
    "    try:\n",
    "        #manual_country_code[i] = country_codes_dict[df2['manual_country'][i]]\n",
    "        manual_country_code[i] = df2['manual_country'][i]\n",
    "    except:\n",
    "        manual_country_code[i] = ''\n",
    "        \n",
    "df2['manual_country_code'] = list(manual_country_code.values())\n",
    "\n",
    "for i in range(0,len(df2)):\n",
    "    if df2['manual_country_code'][i]!=df2['pred_country_flashgeotext'][i]:\n",
    "        print(i,str(df2['manual_country_code'][i]),df2['pred_country_flashgeotext'][i])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "#j = 963\n",
    "j = 67\n",
    "\n",
    "\n",
    "pp.pprint(list_preds[j])\n",
    "print('\\n')\n",
    "print(df['pred_country_flashgeotext'][j],'\\n')\n",
    "print(df['pred_country_list_flashgeotext'][j],'\\n')\n",
    "print(df['cleaned_text'][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['cleaned_text'][j][822:826])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['pred_country_flashgeotext'][53],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df['pred_country_list_flashgeotext'][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "predicted_country_list = list(df['pred_country_list_flashgeotext'][j].keys())\n",
    "for i in range(0,len(predicted_country_list)):\n",
    "    predicted_country_list[i] = predicted_country_list[i][0:2]\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_country_list = list(dict.fromkeys(predicted_country_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(predicted_country_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predicted_country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['manual_country'][16] = 'Ukraine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import spacy \n",
    "\n",
    "cleaned_text_temp = df2['cleaned_text'][12]\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "\n",
    "text_for_spacy = cleaned_text_temp\n",
    "doc = nlp(cleaned_text_temp) \n",
    "joined_sentence = ''\n",
    "for token in doc: \n",
    "    joined_sentence += token.lemma_ + ' '\n",
    "joined_sentence = joined_sentence.replace('\\n','')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#joined_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(700, 800):\n",
    "    print(i, \"possible:\", df['possible_cities'][i], '\\n', \"predicted:\", list_of_predicted_cities[i],\n",
    "          df['pred_country_flashgeotext'][i], '\\n\\n',df['cleaned_text'][i][0:150],'\\n\\n')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df['pred_country_list_flashgeotext'][8],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GeoText2('Uruguay').country_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
